"""
Walk-Forward Validation

ì‹œê³„ì—´ ë°ì´í„°ë¥¼ ìœ„í•œ walk-forward validation
"""

import pandas as pd
import numpy as np
from datetime import datetime
from dateutil.relativedelta import relativedelta
import logging
from typing import Dict, List, Any, Optional, Callable


class WalkForwardValidator:
    """
    Walk-Forward Validation

    ì˜ˆì‹œ (train_months=24, test_months=3):
    Period 1: Train(2020-01~2021-12) â†’ Test(2022-01~2022-03)
    Period 2: Train(2020-04~2022-03) â†’ Test(2022-04~2022-06)  â† ëª¨ë¸ ì¬í•™ìŠµ
    Period 3: Train(2020-07~2022-06) â†’ Test(2022-07~2022-09)  â† ëª¨ë¸ ì¬í•™ìŠµ
    ...

    ë§¤ ê¸°ê°„ë§ˆë‹¤ ëª¨ë¸ì„ ë‹¤ì‹œ í•™ìŠµí•˜ì—¬ ì‹œì¥ ë³€í™”ì— ì ì‘
    """

    def __init__(self,
                 train_months: int = 24,
                 test_months: int = 3,
                 retrain_frequency: int = 3,
                 anchored: bool = False):
        """
        Args:
            train_months: í•™ìŠµ ë°ì´í„° ê¸°ê°„ (ê°œì›”)
            test_months: í…ŒìŠ¤íŠ¸ ë°ì´í„° ê¸°ê°„ (ê°œì›”)
            retrain_frequency: ì¬í•™ìŠµ ë¹ˆë„ (ê°œì›”)
            anchored: Trueë©´ train ì‹œì‘ì  ê³ ì •, Falseë©´ rolling window
        """
        self.train_months = train_months
        self.test_months = test_months
        self.retrain_frequency = retrain_frequency
        self.anchored = anchored

    def generate_windows(self,
                        start_date: datetime,
                        end_date: datetime) -> List[Dict[str, datetime]]:
        """
        í•™ìŠµ/í…ŒìŠ¤íŠ¸ ìœˆë„ìš° ìƒì„±

        Args:
            start_date: ì‹œì‘ ë‚ ì§œ
            end_date: ì¢…ë£Œ ë‚ ì§œ

        Returns:
            ìœˆë„ìš° ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        windows = []
        current_date = start_date + relativedelta(months=self.train_months)
        train_start = start_date

        while current_date < end_date:
            # í•™ìŠµ ê¸°ê°„
            if not self.anchored:
                # Rolling window: í•™ìŠµ ì‹œì‘ì ë„ ì´ë™
                train_start = current_date - relativedelta(months=self.train_months)
            # Anchored window: í•™ìŠµ ì‹œì‘ì  ê³ ì •

            train_end = current_date

            # í…ŒìŠ¤íŠ¸ ê¸°ê°„
            test_start = current_date
            test_end = current_date + relativedelta(months=self.test_months)

            if test_end > end_date:
                break

            windows.append({
                'train_start': train_start,
                'train_end': train_end,
                'test_start': test_start,
                'test_end': test_end
            })

            # ë‹¤ìŒ ìœˆë„ìš°ë¡œ ì´ë™
            current_date += relativedelta(months=self.retrain_frequency)

        return windows

    def validate(self,
                model_class: Any,
                df: pd.DataFrame,
                date_col: str,
                feature_cols: List[str],
                target_col: str,
                start_date: datetime,
                end_date: datetime,
                model_params: Optional[Dict] = None,
                verbose: bool = True) -> pd.DataFrame:
        """
        Walk-forward validation ìˆ˜í–‰

        Args:
            model_class: ëª¨ë¸ í´ë˜ìŠ¤ (ì¸ìŠ¤í„´ìŠ¤í™” ê°€ëŠ¥í•´ì•¼ í•¨)
            df: ì „ì²´ ë°ì´í„°í”„ë ˆì„
            date_col: ë‚ ì§œ ì»¬ëŸ¼ëª…
            feature_cols: í”¼ì²˜ ì»¬ëŸ¼ ë¦¬ìŠ¤íŠ¸
            target_col: íƒ€ê²Ÿ ì»¬ëŸ¼ëª…
            start_date: ì‹œì‘ ë‚ ì§œ
            end_date: ì¢…ë£Œ ë‚ ì§œ
            model_params: ëª¨ë¸ íŒŒë¼ë¯¸í„°
            verbose: ìƒì„¸ ë¡œê·¸ ì¶œë ¥ ì—¬ë¶€

        Returns:
            ê²°ê³¼ ë°ì´í„°í”„ë ˆì„
        """
        if model_params is None:
            model_params = {}

        windows = self.generate_windows(start_date, end_date)

        if verbose:
            logging.info(f"\n{'='*60}")
            logging.info(f"Walk-Forward Validation ì‹œì‘")
            logging.info(f"ì´ {len(windows)}ê°œ ìœˆë„ìš°")
            logging.info(f"í•™ìŠµ ê¸°ê°„: {self.train_months}ê°œì›”")
            logging.info(f"í…ŒìŠ¤íŠ¸ ê¸°ê°„: {self.test_months}ê°œì›”")
            logging.info(f"ì¬í•™ìŠµ ë¹ˆë„: {self.retrain_frequency}ê°œì›”")
            logging.info(f"ìœˆë„ìš° íƒ€ì…: {'Anchored' if self.anchored else 'Rolling'}")
            logging.info(f"{'='*60}\n")

        results = []

        for i, window in enumerate(windows, 1):
            if verbose:
                logging.info(f"\n{'='*60}")
                logging.info(f"Window {i}/{len(windows)}")
                logging.info(f"  Train: {window['train_start'].strftime('%Y-%m-%d')} ~ {window['train_end'].strftime('%Y-%m-%d')}")
                logging.info(f"  Test:  {window['test_start'].strftime('%Y-%m-%d')} ~ {window['test_end'].strftime('%Y-%m-%d')}")

            # ë°ì´í„° ë¶„í• 
            train_mask = (df[date_col] >= window['train_start']) & \
                        (df[date_col] < window['train_end'])
            test_mask = (df[date_col] >= window['test_start']) & \
                       (df[date_col] < window['test_end'])

            train_df = df[train_mask].copy()
            test_df = df[test_mask].copy()

            if len(train_df) == 0 or len(test_df) == 0:
                logging.warning(f"  âš ï¸ Empty data in window {i}, skipping...")
                continue

            if verbose:
                logging.info(f"  Train samples: {len(train_df):,}")
                logging.info(f"  Test samples:  {len(test_df):,}")

            # ëª¨ë¸ ì¬í•™ìŠµ â­ í•µì‹¬!
            try:
                model = model_class(**model_params)

                X_train = train_df[feature_cols]
                y_train = train_df[target_col]
                X_test = test_df[feature_cols]
                y_test = test_df[target_col]

                # NaN ì œê±°
                train_valid_mask = ~(X_train.isnull().any(axis=1) | y_train.isnull())
                test_valid_mask = ~(X_test.isnull().any(axis=1) | y_test.isnull())

                X_train = X_train[train_valid_mask]
                y_train = y_train[train_valid_mask]
                X_test = X_test[test_valid_mask]
                y_test = y_test[test_valid_mask]

                if len(X_train) == 0 or len(X_test) == 0:
                    logging.warning(f"  âš ï¸ No valid data after NaN removal, skipping...")
                    continue

                # í•™ìŠµ
                if verbose:
                    logging.info(f"  ğŸ”„ ëª¨ë¸ í•™ìŠµ ì¤‘...")

                model.fit(X_train, y_train, verbose=0)

                # í‰ê°€
                metrics = model.evaluate(X_test, y_test)

                result = {
                    'window': i,
                    'train_start': window['train_start'],
                    'train_end': window['train_end'],
                    'test_start': window['test_start'],
                    'test_end': window['test_end'],
                    'train_samples': len(X_train),
                    'test_samples': len(X_test),
                    **metrics
                }

                results.append(result)

                if verbose:
                    logging.info(f"  ğŸ“Š Performance:")
                    for metric, value in metrics.items():
                        logging.info(f"     {metric}: {value:.4f}")

            except Exception as e:
                logging.error(f"  âŒ Error in window {i}: {str(e)}")
                continue

        # ê²°ê³¼ ìš”ì•½
        if not results:
            logging.error("No valid results from walk-forward validation!")
            return pd.DataFrame()

        results_df = pd.DataFrame(results)

        if verbose:
            logging.info(f"\n{'='*60}")
            logging.info("Walk-Forward Validation ê²°ê³¼ ìš”ì•½")
            logging.info(f"{'='*60}")
            logging.info(f"\n{results_df.to_string()}\n")

            # í‰ê·  ì„±ëŠ¥
            metric_cols = [col for col in results_df.columns if col not in [
                'window', 'train_start', 'train_end', 'test_start', 'test_end',
                'train_samples', 'test_samples'
            ]]

            logging.info("í‰ê·  ì„±ëŠ¥:")
            for metric in metric_cols:
                mean_val = results_df[metric].mean()
                std_val = results_df[metric].std()
                logging.info(f"  {metric}: {mean_val:.4f} Â± {std_val:.4f}")

        return results_df

    def validate_with_custom_model(self,
                                   train_func: Callable,
                                   evaluate_func: Callable,
                                   df: pd.DataFrame,
                                   date_col: str,
                                   start_date: datetime,
                                   end_date: datetime,
                                   **kwargs) -> pd.DataFrame:
        """
        ì‚¬ìš©ì ì •ì˜ í•™ìŠµ/í‰ê°€ í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•œ walk-forward validation

        Args:
            train_func: í•™ìŠµ í•¨ìˆ˜ (train_df ì…ë ¥, model ë°˜í™˜)
            evaluate_func: í‰ê°€ í•¨ìˆ˜ (model, test_df ì…ë ¥, metrics dict ë°˜í™˜)
            df: ì „ì²´ ë°ì´í„°í”„ë ˆì„
            date_col: ë‚ ì§œ ì»¬ëŸ¼ëª…
            start_date: ì‹œì‘ ë‚ ì§œ
            end_date: ì¢…ë£Œ ë‚ ì§œ
            **kwargs: train_func, evaluate_funcì— ì „ë‹¬í•  ì¶”ê°€ ì¸ì

        Returns:
            ê²°ê³¼ ë°ì´í„°í”„ë ˆì„
        """
        windows = self.generate_windows(start_date, end_date)
        results = []

        for i, window in enumerate(windows, 1):
            logging.info(f"\nWindow {i}/{len(windows)}")
            logging.info(f"  Train: {window['train_start']} ~ {window['train_end']}")
            logging.info(f"  Test:  {window['test_start']} ~ {window['test_end']}")

            # ë°ì´í„° ë¶„í• 
            train_mask = (df[date_col] >= window['train_start']) & \
                        (df[date_col] < window['train_end'])
            test_mask = (df[date_col] >= window['test_start']) & \
                       (df[date_col] < window['test_end'])

            train_df = df[train_mask].copy()
            test_df = df[test_mask].copy()

            if len(train_df) == 0 or len(test_df) == 0:
                logging.warning(f"  âš ï¸ Empty data, skipping...")
                continue

            try:
                # ì‚¬ìš©ì ì •ì˜ í•™ìŠµ
                model = train_func(train_df, **kwargs)

                # ì‚¬ìš©ì ì •ì˜ í‰ê°€
                metrics = evaluate_func(model, test_df, **kwargs)

                result = {
                    'window': i,
                    'train_start': window['train_start'],
                    'test_start': window['test_start'],
                    **metrics
                }

                results.append(result)

                logging.info(f"  ğŸ“Š Performance: {metrics}")

            except Exception as e:
                logging.error(f"  âŒ Error: {str(e)}")
                continue

        return pd.DataFrame(results)
