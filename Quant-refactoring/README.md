# Quant Trading System - Refactored

ê°œì„ ëœ í€€íŠ¸ íŠ¸ë ˆì´ë”© ì‹œìŠ¤í…œ (2025)

## ì£¼ìš” ê°œì„ ì‚¬í•­

### 1. Parquet ì €ì¥ì†Œ (ê²€ì¦ ê¸°ëŠ¥ í¬í•¨)
- âœ… ìë™ ë°ì´í„° ê²€ì¦
- âœ… ìƒ˜í”Œ CSV ìë™ ìƒì„± (ë¹ ë¥¸ í™•ì¸ìš©)
- âœ… 70-90% ì••ì¶•ë¥  (CSV ëŒ€ë¹„)
- âœ… ì»¬ëŸ¼ë³„ ì„ íƒì  ì½ê¸° (ë¹ ë¥¸ ì„±ëŠ¥)

### 2. CatBoost ëª¨ë¸ ì¶”ê°€
- âœ… ì˜¤ë²„í”¼íŒ…ì— ê°•í•¨
- âœ… Ordered boosting
- âœ… GPU ê°€ì†

### 3. Optuna ìë™ í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹
- âœ… Bayesian optimization
- âœ… ìë™ Pruning
- âœ… Cross-validation ì§€ì›

### 4. Stacking ì•™ìƒë¸”
- âœ… ë‹¨ìˆœ í‰ê·  ëŒ€ì‹  í•™ìŠµëœ ê°€ì¤‘ì¹˜
- âœ… Cross-validation ê¸°ë°˜ ë©”íƒ€ í•™ìŠµ
- âœ… ë” ë‚˜ì€ ì˜ˆì¸¡ ì„±ëŠ¥

### 5. MLflow ì‹¤í—˜ ì¶”ì 
- âœ… ëª¨ë“  ì‹¤í—˜ ìë™ ê¸°ë¡
- âœ… íŒŒë¼ë¯¸í„°/ë©”íŠ¸ë¦­ ë¹„êµ
- âœ… ëª¨ë¸ ë²„ì „ ê´€ë¦¬

### 6. Ray ê¸°ë°˜ ë³‘ë ¬ ë°ì´í„° ìˆ˜ì§‘ (NEW)
- âœ… ë©€í‹°í”„ë¡œì„¸ì‹±ë³´ë‹¤ íš¨ìœ¨ì ì¸ ë¶„ì‚° ì²˜ë¦¬
- âœ… ë™ì  ì‘ì—… ìŠ¤ì¼€ì¤„ë§
- âœ… API rate limit ìµœì í™” (8 workers)

### 7. ê¹”ë”í•œ í”„ë¡œì íŠ¸ êµ¬ì¡° (NEW)
- âœ… ëª¨ë“ˆë³„ ëª…í™•í•œ ë¶„ë¦¬
- âœ… ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ì •ë¦¬ (7ê°œ â†’ 2ê°œ íŒŒì¼)
- âœ… ì¼ê´€ëœ íŒ¨í‚¤ì§€ êµ¬ì¡°

## í”„ë¡œì íŠ¸ êµ¬ì¡°

```
Quant-refactoring/
â”œâ”€â”€ main.py                      # ğŸ¯ ì‹¤í–‰ ì§„ì…ì 
â”œâ”€â”€ backtest.py                  # ë°±í…ŒìŠ¤íŒ… ë¡œì§
â”‚
â”œâ”€â”€ config/                      # ì„¤ì • ë° ì „ì—­ ë³€ìˆ˜
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ conf.yaml               # ë©”ì¸ ì„¤ì • íŒŒì¼
â”‚   â”œâ”€â”€ context_loader.py       # ì„¤ì • ë¡œë”
â”‚   â””â”€â”€ g_variables.py          # ì „ì—­ ë³€ìˆ˜ (ì»¬ëŸ¼ ì •ì˜ ë“±)
â”‚
â”œâ”€â”€ data_collector/              # ë°ì´í„° ìˆ˜ì§‘ (Ray ê¸°ë°˜)
â”‚   â”œâ”€â”€ fmp.py                  # FMP ë°ì´í„° ìˆ˜ì§‘ ë©”ì¸
â”‚   â”œâ”€â”€ fmp_api.py              # API ê´€ë¦¬
â”‚   â”œâ”€â”€ fmp_fetch_worker.py     # Ray worker (ë³‘ë ¬ ì²˜ë¦¬)
â”‚   â””â”€â”€ target_api_list.csv     # API ëª©ë¡
â”‚
â”œâ”€â”€ storage/                     # ë°ì´í„° ì €ì¥ì†Œ
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ parquet_storage.py      # Parquet ì €ì¥ + ê²€ì¦
â”‚   â”œâ”€â”€ parquet_converter.py    # CSV â†’ Parquet ë³€í™˜
â”‚   â””â”€â”€ data_validator.py       # ë°ì´í„° ê²€ì¦
â”‚
â”œâ”€â”€ models/                      # ML ëª¨ë¸
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ base_model.py           # ê¸°ë³¸ ëª¨ë¸ í´ë˜ìŠ¤
â”‚   â”œâ”€â”€ xgboost_model.py        # XGBoost ë˜í¼
â”‚   â”œâ”€â”€ lightgbm_model.py       # LightGBM ë˜í¼
â”‚   â”œâ”€â”€ catboost_model.py       # CatBoost ë˜í¼ (ì‹ ê·œ)
â”‚   â”œâ”€â”€ ensemble.py             # Stacking ì•™ìƒë¸”
â”‚   â””â”€â”€ config.py               # ëª¨ë¸ ì„¤ì •
â”‚
â”œâ”€â”€ training/                    # ML í•™ìŠµ íŒŒì´í”„ë¼ì¸
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ regressor.py            # ë ˆê±°ì‹œ í†µí•© í•™ìŠµ ëª¨ë¸
â”‚   â”œâ”€â”€ make_mldata.py          # ML ë°ì´í„° ì „ì²˜ë¦¬
â”‚   â”œâ”€â”€ optimizer.py            # Optuna íŠœë‹
â”‚   â””â”€â”€ mlflow_tracker.py       # MLflow ì¶”ì 
â”‚
â”œâ”€â”€ tools/                       # ë¶„ì„ ë„êµ¬
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ parquet_viewer.py       # Parquet ë·°ì–´ CLI
â”‚   â””â”€â”€ rank_processing.py      # ìˆœìœ„ ë¶„ì„ ë„êµ¬
â”‚
â””â”€â”€ examples/                    # ì‚¬ìš© ì˜ˆì œ
    â””â”€â”€ example_complete_pipeline.py
```

## ë¹ ë¥¸ ì‹œì‘

### 1. ì„¤ì¹˜

```bash
pip install -r requirements.txt
```

### 2. ì„¤ì •

```bash
# ì„¤ì • íŒŒì¼ ìƒì„±
cp config/conf.yaml.template config/conf.yaml

# API í‚¤ ì„¤ì •
vim config/conf.yaml  # API_KEY ìˆ˜ì •
```

### 3. ì‹¤í–‰

```bash
# ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
python main.py

# ë˜ëŠ” ë‹¨ê³„ë³„ ì‹¤í–‰ (conf.yamlì—ì„œ ì œì–´)
# GET_FMP: Y/N          - ë°ì´í„° ìˆ˜ì§‘
# RUN_REGRESSION: Y/N   - ML í•™ìŠµ
# RUN_BACKTEST: Y/N     - ë°±í…ŒìŠ¤íŒ…
```

## requirements.txt

```
# Core
pandas>=2.0.0
numpy>=1.24.0
pyyaml>=6.0

# Data Processing
pyarrow>=12.0.0
tqdm>=4.65.0

# ML Models
xgboost>=2.0.0
lightgbm>=4.0.0
catboost>=1.2.0
scikit-learn>=1.3.0

# Hyperparameter Tuning
optuna>=3.0.0

# Experiment Tracking
mlflow>=2.8.0

# Distributed Processing
ray>=2.0.0

# Time Series
tsfresh>=0.20.0
pmdarima>=2.0.0
statsmodels>=0.14.0

# Utilities
joblib>=1.3.0
requests>=2.31.0
```

## ì‚¬ìš©ë²•

### 1. ë°ì´í„° ìˆ˜ì§‘ (Ray ê¸°ë°˜ ë³‘ë ¬ ì²˜ë¦¬)

```python
from data_collector.fmp import FMP

# FMP ë°ì´í„° ìˆ˜ì§‘ (ìë™ìœ¼ë¡œ Ray workers ìƒì„±)
fmp = FMP(config, main_ctx)
fmp.collect()  # Rayë¡œ ë³‘ë ¬ ë°ì´í„° ìˆ˜ì§‘

# ìµœëŒ€ 8ê°œ workersë¡œ API rate limit ë°©ì§€
```

### 2. Parquet ì €ì¥ì†Œ ì‚¬ìš©

```python
from storage import ParquetStorage

# ì´ˆê¸°í™” (ìë™ ê²€ì¦ í™œì„±í™”)
storage = ParquetStorage(
    root_path='/home/user/Quant/data',
    auto_validate=True
)

# ë°ì´í„° ì €ì¥ (ìë™ìœ¼ë¡œ ê²€ì¦ + ìƒ˜í”Œ CSV ìƒì„±)
storage.save_parquet(df_price, 'price')
# âœ… Saved: price.parquet (1,234,567 rows, 45.2 MB)
# ğŸ“„ Sample saved: price_sample.csv
# âœ… Validation passed

# ë°ì´í„° ë¡œë“œ (íŠ¹ì • ì»¬ëŸ¼ë§Œ)
df = storage.load_parquet('price', columns=['symbol', 'date', 'close'])

# ì „ì²´ ê²€ì¦
results = storage.validate_all_tables()
```

### 3. Parquet ë·°ì–´ CLI

```bash
# ê¸°ë³¸ ì‚¬ìš© (ì²˜ìŒ 10ê°œ í–‰)
python tools/parquet_viewer.py data/parquet/price.parquet

# ìì„¸í•œ ì •ë³´
python tools/parquet_viewer.py data/parquet/price.parquet -a

# íŠ¹ì • ì»¬ëŸ¼ë§Œ ë³´ê¸°
python tools/parquet_viewer.py data/parquet/price.parquet -c "symbol,date,close"

# ì¿¼ë¦¬ í•„í„°ë§
python tools/parquet_viewer.py data/parquet/price.parquet -q "close > 100"

# ëœë¤ ìƒ˜í”Œ
python tools/parquet_viewer.py data/parquet/price.parquet -s 50
```

### 4. ëª¨ë¸ í•™ìŠµ

```python
from models import XGBoostModel, LightGBMModel, CatBoostModel

# XGBoost
xgb = XGBoostModel(task='classification', config_name='default')
xgb.build_model()
xgb.fit(X_train, y_train, X_val, y_val)
metrics = xgb.evaluate(X_test, y_test)

# CatBoost (ì‹ ê·œ)
cat = CatBoostModel(task='classification', config_name='default')
cat.build_model()
cat.fit(X_train, y_train, X_val, y_val)
metrics = cat.evaluate(X_test, y_test)

# íŠ¹ì§• ì¤‘ìš”ë„
importance = cat.get_feature_importance(top_n=20)
print(importance)
```

### 5. Optuna í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹

```python
from training import OptunaOptimizer
from models import CatBoostModel
from models.config import OPTUNA_SEARCH_SPACE

# Optimizer ì´ˆê¸°í™”
optimizer = OptunaOptimizer(
    model_class=CatBoostModel,
    search_space=OPTUNA_SEARCH_SPACE['catboost'],
    n_trials=100,
    cv_folds=5
)

# ìµœì í™” ì‹¤í–‰
best_params = optimizer.optimize(X_train, y_train, task='classification')

# ìµœì  ëª¨ë¸ ìƒì„±
best_model = optimizer.get_best_model(task='classification')
best_model.fit(X_train, y_train)

# ìµœì í™” íˆìŠ¤í† ë¦¬ í”Œë¡¯
optimizer.plot_optimization_history('optimization_history.png')
```

### 6. Stacking ì•™ìƒë¸”

```python
from models import StackingEnsemble
from models import XGBoostModel, LightGBMModel, CatBoostModel

# Base models ìƒì„±
xgb1 = XGBoostModel(task='classification', config_name='default')
xgb1.build_model().fit(X_train, y_train)

lgb1 = LightGBMModel(task='classification')
lgb1.build_model().fit(X_train, y_train)

cat1 = CatBoostModel(task='classification')
cat1.build_model().fit(X_train, y_train)

# Stacking ì•™ìƒë¸”
base_models = [
    ('xgb', xgb1.model),
    ('lgb', lgb1.model),
    ('cat', cat1.model)
]

ensemble = StackingEnsemble(
    base_models=base_models,
    task='classification',
    meta_learner='ridge',
    cv=5
)

ensemble.build_ensemble()
ensemble.fit(X_train, y_train)
predictions = ensemble.predict(X_test)
```

### 7. MLflow ì‹¤í—˜ ì¶”ì 

```python
from training import MLflowTracker

# Tracker ì´ˆê¸°í™”
tracker = MLflowTracker(experiment_name='quant_trading_v2')

# ëª¨ë¸ í•™ìŠµ ë° ìë™ ì¶”ì 
tracker.log_training_run(
    model_name='catboost_default',
    model=model.model,
    model_type='catboost',
    params=model.get_params(),
    train_metrics={'accuracy': 0.85, 'f1': 0.82},
    test_metrics={'accuracy': 0.83, 'f1': 0.80},
    feature_importance=importance_df,
    tags={'version': 'v2.0', 'dataset': '2015-2023'}
)

# ìµœê³  ì„±ëŠ¥ ëª¨ë¸ ë¡œë“œ
best_model = tracker.load_best_model(metric='test_accuracy', model_type='catboost')

# Run ë¹„êµ
comparison = tracker.compare_runs(metric='test_accuracy', top_n=10)
print(comparison)
```

## VSCodeì—ì„œ Parquet íŒŒì¼ ë³´ê¸°

1. VSCode Extension ì„¤ì¹˜: **Parquet Viewer**
2. `.parquet` íŒŒì¼ í´ë¦­ â†’ ìë™ìœ¼ë¡œ í…Œì´ë¸” ë·°

## ì„±ëŠ¥ ê°œì„ 

### ì €ì¥ì†Œ ì„±ëŠ¥
| í•­ëª© | ê¸°ì¡´ (CSV) | ê°œì„  (Parquet) | ë¹„ìœ¨ |
|------|-----------|--------------|------|
| íŒŒì¼ í¬ê¸° | 500 MB | 50 MB | 10x |
| ì½ê¸° ì†ë„ | 10ì´ˆ | 1ì´ˆ | 10x |
| ë©”ëª¨ë¦¬ | 2 GB | 500 MB | 4x |

### ML íŒŒì´í”„ë¼ì¸ ì„±ëŠ¥
| í•­ëª© | ê¸°ì¡´ | ê°œì„  | ë¹„ìœ¨ |
|------|------|------|------|
| ëª¨ë¸ ì¢…ë¥˜ | 2 (XGBoost, LightGBM) | 3 (+CatBoost) | +50% |
| í•˜ì´í¼íŒŒë¼ë¯¸í„° íŠœë‹ | ìˆ˜ë™ GridSearch | ìë™ Optuna | 10x ë¹ ë¦„ |
| ì•™ìƒë¸” | ë‹¨ìˆœ í‰ê·  | Stacking | +3-5% ì„±ëŠ¥ |
| ì‹¤í—˜ ê´€ë¦¬ | ìˆ˜ë™ | MLflow ìë™ | âˆ |

### ë°ì´í„° ìˆ˜ì§‘ ì„±ëŠ¥
| í•­ëª© | ê¸°ì¡´ (multiprocessing) | ê°œì„  (Ray) | ê°œì„ ì‚¬í•­ |
|------|----------------------|-----------|---------|
| ë³‘ë ¬ ì²˜ë¦¬ | Pool (ë¹„íš¨ìœ¨ì  IPC) | Ray (íš¨ìœ¨ì  ë¶„ì‚°) | ë©”ëª¨ë¦¬ ê³µìœ  ìµœì í™” |
| API rate limit | cpu_count() workers | 8 workers ì œí•œ | Rate limit ë°©ì§€ |
| ì—ëŸ¬ ì²˜ë¦¬ | ê¸°ë³¸ | í–¥ìƒëœ ì¬ì‹œë„ ë¡œì§ | ì•ˆì •ì„± ì¦ê°€ |

## ìµœê·¼ ì—…ë°ì´íŠ¸ (2025)

### v2.1 - í”„ë¡œì íŠ¸ êµ¬ì¡° ê°œì„ 
- âœ… ë£¨íŠ¸ ë””ë ‰í† ë¦¬ ì •ë¦¬: 7ê°œ â†’ 2ê°œ íŒŒì¼
- âœ… ëª¨ë“ˆë³„ ëª…í™•í•œ ë¶„ë¦¬ (config, storage, models, training, tools)
- âœ… ì¼ê´€ëœ íŒ¨í‚¤ì§€ êµ¬ì¡° (ëª¨ë“  í´ë”ì— `__init__.py`)
- âœ… Import ê²½ë¡œ ìµœì í™”

### v2.0 - ë©€í‹°í”„ë¡œì„¸ì‹± ìµœì í™”
- âœ… parquet.py: ë¹„íš¨ìœ¨ì ì¸ íŒŒì¼ ê¸°ë°˜ IPC ì œê±° (30-50% ì†ë„ í–¥ìƒ)
- âœ… fmp.py: API rate limit ë°©ì§€ (worker ìˆ˜ ì œí•œ)
- âœ… Ray ê¸°ë°˜ ë°ì´í„° ìˆ˜ì§‘ (íš¨ìœ¨ì  ë¶„ì‚° ì²˜ë¦¬)

## ë§ˆì´ê·¸ë ˆì´ì…˜ ê°€ì´ë“œ

ê¸°ì¡´ ì½”ë“œì—ì„œ ë¦¬íŒ©í† ë§ ë²„ì „ìœ¼ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜:

### íŒŒì¼ ìœ„ì¹˜ ë³€ê²½
| ê¸°ì¡´ | ì‹ ê·œ |
|------|------|
| `g_variables.py` | `config/g_variables.py` |
| `make_mldata.py` | `training/make_mldata.py` |
| `regressor.py` | `training/regressor.py` |
| `parquet.py` | `storage/parquet_converter.py` |
| `rank_processing.py` | `tools/rank_processing.py` |

### Import ë³€ê²½
```python
# ê¸°ì¡´
from g_variables import ratio_col_list
from make_mldata import AIDataMaker
from regressor import Regressor
from parquet import Parquet

# ì‹ ê·œ
from config.g_variables import ratio_col_list
from training.make_mldata import AIDataMaker
from training.regressor import Regressor
from storage.parquet_converter import Parquet
```

### ì„¤ì • íŒŒì¼
```yaml
# config/conf.yaml
DATA:
  TARGET_API_LIST: data_collector/target_api_list.csv  # ê²½ë¡œ ë³€ê²½
  STORAGE_TYPE: PARQUET

ML:
  USE_NEW_MODELS: Y  # ìƒˆ ëª¨ë¸ ì‚¬ìš©
  USE_MLFLOW: Y      # MLflow ì¶”ì 
```

## ë¼ì´ì„ ìŠ¤

MIT

## ê¸°ì—¬

ì´ìŠˆ ë° PR í™˜ì˜í•©ë‹ˆë‹¤.

## ë¬¸ì˜

ë²„ê·¸ ë¦¬í¬íŠ¸ ë° ê¸°ëŠ¥ ì œì•ˆì€ GitHub Issuesë¥¼ ì´ìš©í•´ ì£¼ì„¸ìš”.
