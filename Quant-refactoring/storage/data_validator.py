"""Parquet íŒŒì¼ì„ ìœ„í•œ ë°ì´í„° ê²€ì¦ ëª¨ë“ˆì…ë‹ˆë‹¤.

ì´ ëª¨ë“ˆì€ ê¸ˆìœµ ë°ì´í„° íŒŒì´í”„ë¼ì¸ì—ì„œ ì‚¬ìš©ë˜ëŠ” Parquet íŒŒì¼ì— ëŒ€í•œ í¬ê´„ì ì¸
ë°ì´í„° í’ˆì§ˆ ê²€ì¦ì„ ì œê³µí•©ë‹ˆë‹¤. ìŠ¤í‚¤ë§ˆ ì¤€ìˆ˜, ë°ì´í„° íƒ€ì…, null ê°’, ë°ì´í„° í’ˆì§ˆ ë©”íŠ¸ë¦­,
ë„ë©”ì¸ íŠ¹ì • ë¹„ì¦ˆë‹ˆìŠ¤ ê·œì¹™ì„ ê²€ì¦í•©ë‹ˆë‹¤.

DataValidator í´ë˜ìŠ¤ëŠ” ë‹¤ì–‘í•œ í…Œì´ë¸” ìœ í˜•ì— ëŒ€í•œ ì„¤ì • ê°€ëŠ¥í•œ ê²€ì¦ ê·œì¹™ì„ êµ¬í˜„í•˜ê³ 
ì˜¤ë¥˜, ê²½ê³ , í†µê³„ë¥¼ í¬í•¨í•œ ìƒì„¸í•œ ê²€ì¦ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

ê²€ì¦ í•­ëª©:
    - í•„ìˆ˜ ì»¬ëŸ¼ ì¡´ì¬ ì—¬ë¶€
    - ì¤‘ìš” ì»¬ëŸ¼ì˜ null ê°’ ê²€ì¦
    - ìµœì†Œ í–‰ ìˆ˜ ì„ê³„ê°’
    - ë°ì´í„° íƒ€ì… ê²€ì¦ (íŠ¹íˆ datetime ì»¬ëŸ¼)
    - ì¤‘ë³µ ê°ì§€
    - ë°ì´í„° í’ˆì§ˆ ë©”íŠ¸ë¦­ (null ë¹„ìœ¨ ë“±)
    - ë‚ ì§œ ë²”ìœ„ ê²€ì¦

ì‚¬ìš© ì˜ˆì‹œ:
    ê¸°ë³¸ ê²€ì¦ ì›Œí¬í”Œë¡œìš°::

        from storage import DataValidator
        import pandas as pd

        # ê²€ì¦ê¸° ì´ˆê¸°í™”
        validator = DataValidator()

        # ë‹¨ì¼ íŒŒì¼ ê²€ì¦
        result = validator.validate_file(
            file_path='/data/parquet/stock_prices.parquet',
            table_name='price'
        )

        if result['passed']:
            print("Validation passed!")
            print(f"Rows: {result['info']['rows']:,}")
        else:
            print("Validation failed:")
            for error in result['errors']:
                print(f"  - {error}")

        # ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  íŒŒì¼ ê²€ì¦
        all_results = validator.validate_all('/data/parquet/')

        # ìƒì„¸ ë³´ê³ ì„œ ìƒì„±
        report_path = validator.generate_report(
            all_results,
            output_file='validation_report.txt'
        )

Attributes:
    Module-level exports: DataValidator
"""

import logging
import pandas as pd
from pathlib import Path
from typing import Dict, List, Optional, Any, Tuple


class DataValidator:
    """Parquet íŒŒì¼ ë°ì´í„° í’ˆì§ˆ ê²€ì¦ê¸°ì…ë‹ˆë‹¤.

    ì´ í´ë˜ìŠ¤ëŠ” ê¸ˆìœµ ë°ì´í„°ë¥¼ í¬í•¨í•˜ëŠ” Parquet íŒŒì¼ì— ëŒ€í•œ í¬ê´„ì ì¸ ê²€ì¦ì„ ì œê³µí•©ë‹ˆë‹¤.
    ì„¤ì • ê°€ëŠ¥í•œ ê·œì¹™ì„ ê¸°ë°˜ìœ¼ë¡œ ìŠ¤í‚¤ë§ˆ ì¤€ìˆ˜, ë°ì´í„° íƒ€ì…, null ê°’, ë°ì´í„° í’ˆì§ˆ ë©”íŠ¸ë¦­ì„
    ê²€ì‚¬í•©ë‹ˆë‹¤.

    ê° í…Œì´ë¸” ìœ í˜•ì€ ë‹¤ìŒì„ ì •ì˜í•˜ëŠ” ìì²´ ê²€ì¦ ê·œì¹™ì„ ê°€ì§‘ë‹ˆë‹¤:
        - ë°˜ë“œì‹œ ì¡´ì¬í•´ì•¼ í•˜ëŠ” í•„ìˆ˜ ì»¬ëŸ¼
        - null ê°’ì„ í¬í•¨í•  ìˆ˜ ì—†ëŠ” ì»¬ëŸ¼
        - ìµœì†Œ í–‰ ìˆ˜ ì„ê³„ê°’
        - í…Œì´ë¸” ëª©ì ì— ëŒ€í•œ ì„¤ëª…

    Attributes:
        validation_rules (Dict[str, Dict[str, Any]]): í…Œì´ë¸” ì´ë¦„ì„ ê²€ì¦ ê·œì¹™ì—
            ë§¤í•‘í•˜ëŠ” ë”•ì…”ë„ˆë¦¬. ê° ê·œì¹™ ì„¸íŠ¸ëŠ” ë‹¤ìŒì„ í¬í•¨í•©ë‹ˆë‹¤:
            - required_columns (List[str]): ë°˜ë“œì‹œ ì¡´ì¬í•´ì•¼ í•˜ëŠ” ì»¬ëŸ¼
            - not_null_columns (List[str]): nullì„ ê°€ì§ˆ ìˆ˜ ì—†ëŠ” ì»¬ëŸ¼
            - min_rows (int): ìµœì†Œ ì˜ˆìƒ í–‰ ìˆ˜
            - description (str): í…Œì´ë¸” ì„¤ëª…

    ì‚¬ìš© ì˜ˆì‹œ:
        ì»¤ìŠ¤í…€ ê·œì¹™ìœ¼ë¡œ ì´ˆê¸°í™”í•˜ê³  ê²€ì¦::

            validator = DataValidator()

            # ì»¤ìŠ¤í…€ ê²€ì¦ ê·œì¹™ ì¶”ê°€
            validator.validation_rules['my_table'] = {
                'required_columns': ['id', 'date', 'value'],
                'not_null_columns': ['id', 'date'],
                'min_rows': 1000,
                'description': 'My custom financial table'
            }

            # ê²€ì¦ ì‹¤í–‰
            result = validator.validate_file('my_table.parquet', 'my_table')

    Note:
        ê²€ì¦ê¸°ëŠ” ì¼ë°˜ì ì¸ ê¸ˆìœµ í…Œì´ë¸”ì— ëŒ€í•œ ê·œì¹™ì´ ì‚¬ì „ ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤:
        symbol_list, price, financial_statement, metrics.
    """

    def __init__(self) -> None:
        """ê¸°ë³¸ ê²€ì¦ ê·œì¹™ìœ¼ë¡œ DataValidatorë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤.

        ì‹¬ë³¼ ë¦¬ìŠ¤íŠ¸, ê°€ê²© ë°ì´í„°, ì¬ë¬´ì œí‘œ, ë©”íŠ¸ë¦­ì„ í¬í•¨í•œ í‘œì¤€ ê¸ˆìœµ ë°ì´í„°
        í…Œì´ë¸”ì— ëŒ€í•œ ê²€ì¦ ê·œì¹™ì„ ì„¤ì •í•©ë‹ˆë‹¤.

        ì‚¬ìš© ì˜ˆì‹œ:
            ê²€ì¦ê¸° ìƒì„± ë° ê·œì¹™ í™•ì¸::

                validator = DataValidator()

                # ì‚¬ìš© ê°€ëŠ¥í•œ í…Œì´ë¸” ê·œì¹™ ë³´ê¸°
                print("Configured tables:", validator.validation_rules.keys())

                # íŠ¹ì • í…Œì´ë¸” ê·œì¹™ ë³´ê¸°
                price_rules = validator.validation_rules['price']
                print(f"Price table requires: {price_rules['required_columns']}")
        """
        # Define validation rules for each table type
        self.validation_rules = {
            'symbol_list': {
                'required_columns': ['symbol', 'exchangeShortName', 'type', 'ipoDate'],
                'not_null_columns': ['symbol', 'exchangeShortName'],
                'min_rows': 1000,
                'description': 'Stock symbol list with exchange and IPO information'
            },
            'price': {
                'required_columns': ['date', 'symbol', 'close', 'volume', 'marketCap'],
                'not_null_columns': ['date', 'symbol', 'close'],
                'min_rows': 100000,
                'description': 'Historical price data with market cap'
            },
            'financial_statement': {
                'required_columns': ['date', 'symbol', 'revenue', 'netIncome'],
                'not_null_columns': ['date', 'symbol'],
                'min_rows': 10000,
                'description': 'Financial statements (income, balance, cashflow)'
            },
            'metrics': {
                'required_columns': ['date', 'symbol', 'peRatio', 'marketCap'],
                'not_null_columns': ['date', 'symbol'],
                'min_rows': 10000,
                'description': 'Key financial metrics and ratios'
            }
        }

    def validate_file(self, file_path: str, table_name: str) -> Dict[str, Any]:
        """ì •ì˜ëœ ê·œì¹™ì— ëŒ€í•´ ë‹¨ì¼ Parquet íŒŒì¼ì„ ê²€ì¦í•©ë‹ˆë‹¤.

        Parquet íŒŒì¼ì— ëŒ€í•´ ìŠ¤í‚¤ë§ˆ ê²€ì¦, ë°ì´í„° íƒ€ì… ê²€ì‚¬, null ê°’ ê°ì§€, ì¤‘ë³µ ê²€ì‚¬,
        ë°ì´í„° í’ˆì§ˆ ë©”íŠ¸ë¦­ì„ í¬í•¨í•œ í¬ê´„ì ì¸ ê²€ì¦ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤. ì˜¤ë¥˜, ê²½ê³ ,
        ì •ë³´ í†µê³„ê°€ í¬í•¨ëœ ìƒì„¸ ê²°ê³¼ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤.

        ê²€ì¦ ë‹¨ê³„:
            1. íŒŒì¼ì„ ë¡œë“œí•˜ê³  ê¸°ë³¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (í–‰, ì»¬ëŸ¼, í¬ê¸°)
            2. í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
            3. ìµœì†Œ í–‰ ìˆ˜ ê²€ì¦
            4. ì¤‘ìš” ì»¬ëŸ¼ì˜ null ê°’ ê²€ì¦
            5. ì¤‘ë³µ ê²€ì‚¬ (symbol_listë§Œ í•´ë‹¹)
            6. ë‚ ì§œ ì»¬ëŸ¼ íƒ€ì… ê²€ì¦
            7. ë°ì´í„° í’ˆì§ˆ ë©”íŠ¸ë¦­ ê³„ì‚°

        Args:
            file_path (str): ê²€ì¦í•  Parquet íŒŒì¼ì˜ ì ˆëŒ€ ê²½ë¡œ.
            table_name (str): ê·œì¹™ ì¡°íšŒë¥¼ ìœ„í•œ í…Œì´ë¸” ìœ í˜• ì´ë¦„.
                validation_rules ë”•ì…”ë„ˆë¦¬ì˜ í‚¤ì™€ ì¼ì¹˜í•´ì•¼ í•©ë‹ˆë‹¤.

        Returns:
            Dict[str, Any]: ë‹¤ìŒì„ í¬í•¨í•˜ëŠ” ê²€ì¦ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬:
                - file (str): ê²€ì¦ëœ íŒŒì¼ ê²½ë¡œ
                - table (str): í…Œì´ë¸” ì´ë¦„
                - passed (bool): ì „ì²´ ê²€ì¦ ìƒíƒœ (ì˜¤ë¥˜ê°€ ì—†ìœ¼ë©´ True)
                - errors (List[str]): ê²€ì¦ ì˜¤ë¥˜ ë¦¬ìŠ¤íŠ¸ (ì°¨ë‹¨ ë¬¸ì œ)
                - warnings (List[str]): ê²½ê³  ë¦¬ìŠ¤íŠ¸ (ë¹„ì°¨ë‹¨ ë¬¸ì œ)
                - info (Dict[str, Any]): ë©”íƒ€ë°ì´í„° ë° í†µê³„:
                    - rows (int): í–‰ ìˆ˜
                    - columns (int): ì»¬ëŸ¼ ìˆ˜
                    - size_mb (float): íŒŒì¼ í¬ê¸° (MB)
                    - memory_mb (float): ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ (MB)
                    - date_range (Tuple[str, str]): ìµœì†Œ ë° ìµœëŒ€ ë‚ ì§œ (date ì»¬ëŸ¼ì´ ìˆëŠ” ê²½ìš°)
                    - unique_symbols (int): ê³ ìœ  ì‹¬ë³¼ ìˆ˜ (symbol ì»¬ëŸ¼ì´ ìˆëŠ” ê²½ìš°)

        ì‚¬ìš© ì˜ˆì‹œ:
            ê²€ì¦ ë° ê²°ê³¼ ë¶„ì„::

                validator = DataValidator()

                # ê°€ê²© íŒŒì¼ ê²€ì¦
                result = validator.validate_file(
                    '/data/parquet/price.parquet',
                    'price'
                )

                # ì „ì²´ ìƒíƒœ í™•ì¸
                if result['passed']:
                    print("âœ… Validation passed")
                    info = result['info']
                    print(f"Data: {info['rows']:,} rows, {info['size_mb']:.2f} MB")
                    print(f"Date range: {info['date_range'][0]} to {info['date_range'][1]}")
                else:
                    print("âŒ Validation failed")

                # ì˜¤ë¥˜ ê²€í† 
                if result['errors']:
                    print("Errors:")
                    for error in result['errors']:
                        print(f"  - {error}")

                # ê²½ê³  ê²€í† 
                if result['warnings']:
                    print("Warnings:")
                    for warning in result['warnings']:
                        print(f"  - {warning}")

        Note:
            - table_nameì— ëŒ€í•œ ê²€ì¦ ê·œì¹™ì´ ì—†ëŠ” ê²½ìš°ì—ë„ ê¸°ë³¸ ê²€ì‚¬ëŠ” ìˆ˜í–‰ë©ë‹ˆë‹¤
            - ì½ì„ ìˆ˜ ì—†ëŠ” íŒŒì¼ì€ passed=False ë° ì˜¤ë¥˜ ë©”ì‹œì§€ë¥¼ ê°€ì§‘ë‹ˆë‹¤
            - ê²½ê³ ëŠ” ê²€ì¦ ì‹¤íŒ¨ë¥¼ ì•¼ê¸°í•˜ì§€ ì•Šì§€ë§Œ ì ì¬ì  ë¬¸ì œë¥¼ ë‚˜íƒ€ëƒ…ë‹ˆë‹¤
        """
        # Initialize results structure
        results = {
            'file': file_path,
            'table': table_name,
            'passed': True,
            'errors': [],
            'warnings': [],
            'info': {}
        }

        try:
            # Load Parquet file
            df = pd.read_parquet(file_path)
            rules = self.validation_rules.get(table_name, {})

            # Collect basic file information
            results['info']['rows'] = len(df)
            results['info']['columns'] = len(df.columns)
            results['info']['size_mb'] = Path(file_path).stat().st_size / 1024**2
            results['info']['memory_mb'] = df.memory_usage(deep=True).sum() / 1024**2

            # 1. Validate required columns are present
            if 'required_columns' in rules:
                missing_cols = set(rules['required_columns']) - set(df.columns)
                if missing_cols:
                    results['errors'].append(f"Missing required columns: {missing_cols}")
                    results['passed'] = False

            # 2. Check minimum row count threshold
            if 'min_rows' in rules:
                if len(df) < rules['min_rows']:
                    results['warnings'].append(
                        f"Row count ({len(df):,}) below minimum ({rules['min_rows']:,})"
                    )

            # 3. Validate null values in critical columns
            if 'not_null_columns' in rules:
                for col in rules['not_null_columns']:
                    if col in df.columns:
                        null_count = df[col].isnull().sum()
                        null_pct = (null_count / len(df)) * 100 if len(df) > 0 else 0
                        if null_count > 0:
                            results['errors'].append(
                                f"Column '{col}' has {null_count:,} null values ({null_pct:.1f}%)"
                            )
                            results['passed'] = False

            # 4. Check for duplicate symbols (symbol_list table only)
            if table_name == 'symbol_list' and 'symbol' in df.columns:
                dup_count = df['symbol'].duplicated().sum()
                if dup_count > 0:
                    results['warnings'].append(f"Duplicate symbols: {dup_count}")

            # 5. Validate date column data type
            if 'date' in df.columns:
                if not pd.api.types.is_datetime64_any_dtype(df['date']):
                    results['errors'].append("'date' column is not datetime type")
                    results['passed'] = False
                else:
                    # Extract date range for valid datetime columns
                    results['info']['date_range'] = (
                        df['date'].min().strftime('%Y-%m-%d'),
                        df['date'].max().strftime('%Y-%m-%d')
                    )

            # 6. Analyze data quality - identify columns with high null percentages
            null_summary = df.isnull().sum()
            high_null_cols = null_summary[null_summary > len(df) * 0.5].to_dict()
            if high_null_cols:
                results['warnings'].append(
                    f"Columns with >50% null values: {list(high_null_cols.keys())[:5]}"
                )

            # 7. Calculate unique symbol count if symbol column exists
            if 'symbol' in df.columns:
                results['info']['unique_symbols'] = df['symbol'].nunique()

        except Exception as e:
            # Handle file read errors or other exceptions
            results['passed'] = False
            results['errors'].append(f"Failed to read file: {str(e)}")

        return results

    def validate_all(self, parquet_dir: str) -> Dict[str, Dict[str, Any]]:
        """ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  Parquet íŒŒì¼ì„ ê²€ì¦í•©ë‹ˆë‹¤.

        ë””ë ‰í† ë¦¬ì—ì„œ Parquet íŒŒì¼ì„ ìŠ¤ìº”í•˜ê³  ê°ê°ì„ ê²€ì¦í•˜ì—¬ ê²°ê³¼ë¥¼ ë¡œê¹…í•˜ê³ 
        ìš”ì•½ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì €ì¥ì†Œ ìœ„ì¹˜ì˜ ëª¨ë“  í…Œì´ë¸”ì— ëŒ€í•œ ë°°ì¹˜ ê²€ì¦ì—
        ìœ ìš©í•©ë‹ˆë‹¤.

        Args:
            parquet_dir (str): Parquet íŒŒì¼ì´ ìˆëŠ” ë””ë ‰í† ë¦¬ ê²½ë¡œ.
                ì´ ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  *.parquet íŒŒì¼ì´ ê²€ì¦ë©ë‹ˆë‹¤.

        Returns:
            Dict[str, Dict[str, Any]]: í…Œì´ë¸” ì´ë¦„ì„ ê²€ì¦ ê²°ê³¼ì— ë§¤í•‘í•˜ëŠ” ë”•ì…”ë„ˆë¦¬.
                ê° ê°’ì€ passed ìƒíƒœ, errors, warnings, infoë¥¼ í¬í•¨í•˜ëŠ”
                validate_file()ì˜ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬ì…ë‹ˆë‹¤.

        ì‚¬ìš© ì˜ˆì‹œ:
            ì „ì²´ ë””ë ‰í† ë¦¬ ê²€ì¦ ë° ìš”ì•½::

                validator = DataValidator()

                # ëª¨ë“  íŒŒì¼ ê²€ì¦
                results = validator.validate_all('/data/parquet/')

                # ì„±ê³µ ë° ì‹¤íŒ¨ ìˆ˜ ê³„ì‚°
                passed = sum(1 for r in results.values() if r['passed'])
                failed = len(results) - passed
                print(f"Results: {passed} passed, {failed} failed")

                # ì‹¤íŒ¨í•œ í…Œì´ë¸” ë‚˜ì—´
                failed_tables = [
                    name for name, result in results.items()
                    if not result['passed']
                ]
                if failed_tables:
                    print(f"Failed tables: {failed_tables}")

                # ì „ì²´ ë°ì´í„° ë³¼ë¥¨ ê°€ì ¸ì˜¤ê¸°
                total_mb = sum(
                    r['info'].get('size_mb', 0)
                    for r in results.values()
                )
                print(f"Total data size: {total_mb:.2f} MB")

        Note:
            - ê²€ì¦ ì¤‘ ê° íŒŒì¼ì— ëŒ€í•œ ìƒì„¸ ì •ë³´ë¥¼ ë¡œê¹…í•©ë‹ˆë‹¤
            - info ë° error ë ˆë²¨ ë¡œê·¸ë¡œ ì§„í–‰ ìƒí™©ì„ í‘œì‹œí•©ë‹ˆë‹¤
            - Parquet íŒŒì¼ì„ ì°¾ì§€ ëª»í•œ ê²½ìš° ë¹ˆ ë”•ì…”ë„ˆë¦¬ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤
            - ì™„ë£Œ ì‹œ ìš”ì•½ í†µê³„ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤
        """
        parquet_path = Path(parquet_dir)
        all_results = {}

        logging.info("="*80)
        logging.info("Starting Parquet Data Validation")
        logging.info("="*80)

        # Find all Parquet files in directory
        parquet_files = list(parquet_path.glob("*.parquet"))
        if not parquet_files:
            logging.warning(f"No parquet files found in {parquet_dir}")
            return all_results

        # Validate each file
        for file_path in parquet_files:
            table_name = file_path.stem
            logging.info(f"\nValidating: {table_name}.parquet")

            # Run validation
            result = self.validate_file(str(file_path), table_name)
            all_results[table_name] = result

            # Log validation result
            if result['passed']:
                logging.info(f"âœ… {table_name}: PASSED")
            else:
                logging.error(f"âŒ {table_name}: FAILED")

            # Log basic information
            info = result['info']
            logging.info(f"   ğŸ“Š Rows: {info.get('rows', 0):,}")
            logging.info(f"   ğŸ“ Size: {info.get('size_mb', 0):.2f} MB")
            logging.info(f"   ğŸ’¾ Memory: {info.get('memory_mb', 0):.2f} MB")

            # Log date range if available
            if 'date_range' in info:
                logging.info(f"   ğŸ“… Date range: {info['date_range'][0]} ~ {info['date_range'][1]}")

            # Log symbol count if available
            if 'unique_symbols' in info:
                logging.info(f"   ğŸ¢ Unique symbols: {info['unique_symbols']:,}")

            # Log all errors
            for error in result['errors']:
                logging.error(f"   ğŸ”´ {error}")

            # Log all warnings
            for warning in result['warnings']:
                logging.warning(f"   ğŸŸ¡ {warning}")

        # Print summary statistics
        logging.info("\n" + "="*80)
        passed = sum(1 for r in all_results.values() if r['passed'])
        total = len(all_results)
        logging.info(f"Validation Summary: {passed}/{total} passed")

        if passed == total:
            logging.info("âœ… All validations passed!")
        else:
            logging.warning(f"âš ï¸  {total - passed} validation(s) failed")

        logging.info("="*80)

        return all_results

    def generate_report(
        self,
        results: Dict[str, Dict[str, Any]],
        output_file: str = "validation_report.txt"
    ) -> str:
        """ê²€ì¦ ê²°ê³¼ë¡œë¶€í„° ìƒì„¸ í…ìŠ¤íŠ¸ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

        ê° í…Œì´ë¸”ì˜ ìƒíƒœ, ë©”íƒ€ë°ì´í„°, ì˜¤ë¥˜, ê²½ê³ ë¥¼ í¬í•¨í•˜ëŠ” í˜•ì‹í™”ëœ ì„¹ì…˜ì´ ìˆëŠ”
        í…ìŠ¤íŠ¸ í˜•ì‹ì˜ í¬ê´„ì ì¸ ê²€ì¦ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ë³´ê³ ì„œëŠ” ê²€ì¦ ê²°ê³¼ë¥¼
        ê³µìœ í•˜ê±°ë‚˜ ë³´ê´€í•˜ëŠ” ë° ì í•©í•©ë‹ˆë‹¤.

        Args:
            results (Dict[str, Dict[str, Any]]): validate_all()ì˜ ê²€ì¦ ê²°ê³¼ ë˜ëŠ”
                ë™ì¼í•œ êµ¬ì¡°ë¡œ ìˆ˜ë™ìœ¼ë¡œ êµ¬ì„±ëœ ë”•ì…”ë„ˆë¦¬.
            output_file (str, optional): ì¶œë ¥ ë³´ê³ ì„œ íŒŒì¼ ê²½ë¡œ. ì ˆëŒ€ ë˜ëŠ”
                ìƒëŒ€ ê²½ë¡œì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ì€ "validation_report.txt".

        Returns:
            str: ìƒì„±ëœ ë³´ê³ ì„œ íŒŒì¼ ê²½ë¡œ.

        ì‚¬ìš© ì˜ˆì‹œ:
            ë³´ê³ ì„œ ìƒì„± ë° ê²€í† ::

                validator = DataValidator()

                # ê²€ì¦ ë° ë³´ê³ ì„œ ìƒì„±
                results = validator.validate_all('/data/parquet/')
                report_path = validator.generate_report(
                    results,
                    output_file='/reports/validation_2024.txt'
                )

                # ë³´ê³ ì„œ ì½ê¸° ë° ì¶œë ¥
                with open(report_path, 'r', encoding='utf-8') as f:
                    print(f.read())

                # íŠ¹ì • í…Œì´ë¸”ì— ëŒ€í•´ì„œë§Œ ë³´ê³ ì„œ ìƒì„±
                subset_results = {
                    k: v for k, v in results.items()
                    if k in ['price', 'symbol_list']
                }
                validator.generate_report(
                    subset_results,
                    'subset_validation.txt'
                )

        Note:
            - ë³´ê³ ì„œëŠ” ìƒë‹¨ì— ì „ì²´ ìš”ì•½ì„ í¬í•¨í•©ë‹ˆë‹¤
            - ê° í…Œì´ë¸”ì€ ì „ì²´ ì„¸ë¶€ ì •ë³´ê°€ ìˆëŠ” ìì²´ ì„¹ì…˜ì„ ê°€ì§‘ë‹ˆë‹¤
            - íŒŒì¼ì€ UTF-8 ì¸ì½”ë”©ìœ¼ë¡œ ì‘ì„±ë©ë‹ˆë‹¤
            - output_file ê²½ë¡œì˜ ê¸°ì¡´ íŒŒì¼ì€ ë®ì–´ì”Œì›Œì§‘ë‹ˆë‹¤
            - ë³´ê³ ì„œ ê²½ë¡œëŠ” ìƒì„± í›„ ë¡œê¹…ë©ë‹ˆë‹¤
        """
        with open(output_file, 'w', encoding='utf-8') as f:
            # Write report header
            f.write("="*80 + "\n")
            f.write("Parquet Data Validation Report\n")
            f.write("="*80 + "\n\n")

            # Write overall summary
            passed = sum(1 for r in results.values() if r['passed'])
            total = len(results)
            f.write(f"Overall: {passed}/{total} tables passed validation\n\n")

            # Write detailed section for each table
            for table_name, result in results.items():
                f.write(f"\n{'='*80}\n")
                f.write(f"Table: {table_name}\n")
                f.write(f"{'='*80}\n")
                f.write(f"Status: {'âœ… PASSED' if result['passed'] else 'âŒ FAILED'}\n")
                f.write(f"File: {result['file']}\n\n")

                # Write basic information section
                f.write("Basic Information:\n")
                info = result['info']
                f.write(f"  - Rows: {info.get('rows', 0):,}\n")
                f.write(f"  - Columns: {info.get('columns', 0)}\n")
                f.write(f"  - File Size: {info.get('size_mb', 0):.2f} MB\n")
                f.write(f"  - Memory Usage: {info.get('memory_mb', 0):.2f} MB\n")

                # Write date range if available
                if 'date_range' in info:
                    f.write(f"  - Date Range: {info['date_range'][0]} ~ {info['date_range'][1]}\n")

                # Write symbol count if available
                if 'unique_symbols' in info:
                    f.write(f"  - Unique Symbols: {info['unique_symbols']:,}\n")

                # Write errors section
                if result['errors']:
                    f.write("\nâŒ Errors:\n")
                    for error in result['errors']:
                        f.write(f"  - {error}\n")

                # Write warnings section
                if result['warnings']:
                    f.write("\nâš ï¸  Warnings:\n")
                    for warning in result['warnings']:
                        f.write(f"  - {warning}\n")

                # Write success message if no issues
                if not result['errors'] and not result['warnings']:
                    f.write("\nâœ… No issues found\n")

                f.write("\n")

        logging.info(f"ğŸ“„ Validation report saved to: {output_file}")
        return output_file
