"""
Data validation module for Parquet files
Validates data integrity, schema, and quality
"""

import logging
import pandas as pd
from pathlib import Path
from typing import Dict, List, Optional


class DataValidator:
    """Parquet ë°ì´í„° ê²€ì¦ í´ë˜ìŠ¤"""

    def __init__(self):
        self.validation_rules = {
            'symbol_list': {
                'required_columns': ['symbol', 'exchangeShortName', 'type', 'ipoDate'],
                'not_null_columns': ['symbol', 'exchangeShortName'],
                'min_rows': 1000,
                'description': 'Stock symbol list with exchange and IPO information'
            },
            'price': {
                'required_columns': ['date', 'symbol', 'close', 'volume', 'marketCap'],
                'not_null_columns': ['date', 'symbol', 'close'],
                'min_rows': 100000,
                'description': 'Historical price data with market cap'
            },
            'financial_statement': {
                'required_columns': ['date', 'symbol', 'revenue', 'netIncome'],
                'not_null_columns': ['date', 'symbol'],
                'min_rows': 10000,
                'description': 'Financial statements (income, balance, cashflow)'
            },
            'metrics': {
                'required_columns': ['date', 'symbol', 'peRatio', 'marketCap'],
                'not_null_columns': ['date', 'symbol'],
                'min_rows': 10000,
                'description': 'Key financial metrics and ratios'
            }
        }

    def validate_file(self, file_path: str, table_name: str) -> Dict:
        """
        ë‹¨ì¼ Parquet íŒŒì¼ ê²€ì¦

        Args:
            file_path: Parquet íŒŒì¼ ê²½ë¡œ
            table_name: í…Œì´ë¸” ì´ë¦„

        Returns:
            ê²€ì¦ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        results = {
            'file': file_path,
            'table': table_name,
            'passed': True,
            'errors': [],
            'warnings': [],
            'info': {}
        }

        try:
            df = pd.read_parquet(file_path)
            rules = self.validation_rules.get(table_name, {})

            # ê¸°ë³¸ ì •ë³´
            results['info']['rows'] = len(df)
            results['info']['columns'] = len(df.columns)
            results['info']['size_mb'] = Path(file_path).stat().st_size / 1024**2
            results['info']['memory_mb'] = df.memory_usage(deep=True).sum() / 1024**2

            # 1. í•„ìˆ˜ ì»¬ëŸ¼ ì²´í¬
            if 'required_columns' in rules:
                missing_cols = set(rules['required_columns']) - set(df.columns)
                if missing_cols:
                    results['errors'].append(f"Missing required columns: {missing_cols}")
                    results['passed'] = False

            # 2. ìµœì†Œ í–‰ ìˆ˜ ì²´í¬
            if 'min_rows' in rules:
                if len(df) < rules['min_rows']:
                    results['warnings'].append(
                        f"Row count ({len(df):,}) below minimum ({rules['min_rows']:,})"
                    )

            # 3. Null ê°’ ì²´í¬ (í•„ìˆ˜ ì»¬ëŸ¼)
            if 'not_null_columns' in rules:
                for col in rules['not_null_columns']:
                    if col in df.columns:
                        null_count = df[col].isnull().sum()
                        null_pct = (null_count / len(df)) * 100 if len(df) > 0 else 0
                        if null_count > 0:
                            results['errors'].append(
                                f"Column '{col}' has {null_count:,} null values ({null_pct:.1f}%)"
                            )
                            results['passed'] = False

            # 4. ì¤‘ë³µ ì²´í¬ (symbol_list)
            if table_name == 'symbol_list' and 'symbol' in df.columns:
                dup_count = df['symbol'].duplicated().sum()
                if dup_count > 0:
                    results['warnings'].append(f"Duplicate symbols: {dup_count}")

            # 5. ë‚ ì§œ íƒ€ì… ì²´í¬
            if 'date' in df.columns:
                if not pd.api.types.is_datetime64_any_dtype(df['date']):
                    results['errors'].append("'date' column is not datetime type")
                    results['passed'] = False
                else:
                    results['info']['date_range'] = (
                        df['date'].min().strftime('%Y-%m-%d'),
                        df['date'].max().strftime('%Y-%m-%d')
                    )

            # 6. ë°ì´í„° í’ˆì§ˆ ì²´í¬
            null_summary = df.isnull().sum()
            high_null_cols = null_summary[null_summary > len(df) * 0.5].to_dict()
            if high_null_cols:
                results['warnings'].append(
                    f"Columns with >50% null values: {list(high_null_cols.keys())[:5]}"
                )

            # 7. ê¸°ë³¸ í†µê³„
            if 'symbol' in df.columns:
                results['info']['unique_symbols'] = df['symbol'].nunique()

        except Exception as e:
            results['passed'] = False
            results['errors'].append(f"Failed to read file: {str(e)}")

        return results

    def validate_all(self, parquet_dir: str) -> Dict:
        """
        ëª¨ë“  Parquet íŒŒì¼ ê²€ì¦

        Args:
            parquet_dir: Parquet íŒŒì¼ë“¤ì´ ìˆëŠ” ë””ë ‰í† ë¦¬

        Returns:
            ì „ì²´ ê²€ì¦ ê²°ê³¼ ë”•ì…”ë„ˆë¦¬
        """
        parquet_path = Path(parquet_dir)
        all_results = {}

        logging.info("="*80)
        logging.info("Starting Parquet Data Validation")
        logging.info("="*80)

        parquet_files = list(parquet_path.glob("*.parquet"))
        if not parquet_files:
            logging.warning(f"No parquet files found in {parquet_dir}")
            return all_results

        for file_path in parquet_files:
            table_name = file_path.stem
            logging.info(f"\nValidating: {table_name}.parquet")

            result = self.validate_file(str(file_path), table_name)
            all_results[table_name] = result

            # ê²°ê³¼ ì¶œë ¥
            if result['passed']:
                logging.info(f"âœ… {table_name}: PASSED")
            else:
                logging.error(f"âŒ {table_name}: FAILED")

            # ì •ë³´ ì¶œë ¥
            info = result['info']
            logging.info(f"   ğŸ“Š Rows: {info.get('rows', 0):,}")
            logging.info(f"   ğŸ“ Size: {info.get('size_mb', 0):.2f} MB")
            logging.info(f"   ğŸ’¾ Memory: {info.get('memory_mb', 0):.2f} MB")

            if 'date_range' in info:
                logging.info(f"   ğŸ“… Date range: {info['date_range'][0]} ~ {info['date_range'][1]}")

            if 'unique_symbols' in info:
                logging.info(f"   ğŸ¢ Unique symbols: {info['unique_symbols']:,}")

            # ì—ëŸ¬ ì¶œë ¥
            for error in result['errors']:
                logging.error(f"   ğŸ”´ {error}")

            # ê²½ê³  ì¶œë ¥
            for warning in result['warnings']:
                logging.warning(f"   ğŸŸ¡ {warning}")

        # ì „ì²´ ìš”ì•½
        logging.info("\n" + "="*80)
        passed = sum(1 for r in all_results.values() if r['passed'])
        total = len(all_results)
        logging.info(f"Validation Summary: {passed}/{total} passed")

        if passed == total:
            logging.info("âœ… All validations passed!")
        else:
            logging.warning(f"âš ï¸  {total - passed} validation(s) failed")

        logging.info("="*80)

        return all_results

    def generate_report(self, results: Dict, output_file: str = "validation_report.txt"):
        """
        ê²€ì¦ ê²°ê³¼ ë¦¬í¬íŠ¸ ìƒì„±

        Args:
            results: validate_all()ì˜ ê²°ê³¼
            output_file: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
        """
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write("="*80 + "\n")
            f.write("Parquet Data Validation Report\n")
            f.write("="*80 + "\n\n")

            # ì „ì²´ ìš”ì•½
            passed = sum(1 for r in results.values() if r['passed'])
            total = len(results)
            f.write(f"Overall: {passed}/{total} tables passed validation\n\n")

            for table_name, result in results.items():
                f.write(f"\n{'='*80}\n")
                f.write(f"Table: {table_name}\n")
                f.write(f"{'='*80}\n")
                f.write(f"Status: {'âœ… PASSED' if result['passed'] else 'âŒ FAILED'}\n")
                f.write(f"File: {result['file']}\n\n")

                # ê¸°ë³¸ ì •ë³´
                f.write("Basic Information:\n")
                info = result['info']
                f.write(f"  - Rows: {info.get('rows', 0):,}\n")
                f.write(f"  - Columns: {info.get('columns', 0)}\n")
                f.write(f"  - File Size: {info.get('size_mb', 0):.2f} MB\n")
                f.write(f"  - Memory Usage: {info.get('memory_mb', 0):.2f} MB\n")

                if 'date_range' in info:
                    f.write(f"  - Date Range: {info['date_range'][0]} ~ {info['date_range'][1]}\n")

                if 'unique_symbols' in info:
                    f.write(f"  - Unique Symbols: {info['unique_symbols']:,}\n")

                # ì—ëŸ¬
                if result['errors']:
                    f.write("\nâŒ Errors:\n")
                    for error in result['errors']:
                        f.write(f"  - {error}\n")

                # ê²½ê³ 
                if result['warnings']:
                    f.write("\nâš ï¸  Warnings:\n")
                    for warning in result['warnings']:
                        f.write(f"  - {warning}\n")

                if not result['errors'] and not result['warnings']:
                    f.write("\nâœ… No issues found\n")

                f.write("\n")

        logging.info(f"ğŸ“„ Validation report saved to: {output_file}")
        return output_file
