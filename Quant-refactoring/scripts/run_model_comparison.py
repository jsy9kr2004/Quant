"""
ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ì‹¤í–‰ ìŠ¤í¬ë¦½íŠ¸

ì—¬ëŸ¬ ëª¨ë¸ ë²„ì „ì„ ë¹„êµí•˜ì—¬ ê°œì„  ì—¬ë¶€ë¥¼ íŒë‹¨í•©ë‹ˆë‹¤.
"""

import sys
import os

sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '../..')))

import pandas as pd
import numpy as np
import logging
from datetime import datetime
from pathlib import Path

from optimization.model_comparator import ModelComparator
from models.xgboost_model import XGBoostModel
from models.lightgbm_model import LightGBMModel
from models.catboost_model import CatBoostModel

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('./logs/model_comparison.log'),
        logging.StreamHandler()
    ]
)


def load_train_test_data(data_path='./VIEW', train_ratio=0.8):
    """
    í•™ìŠµ/í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ

    Args:
        data_path: ë°ì´í„° ë””ë ‰í† ë¦¬
        train_ratio: í•™ìŠµ ë°ì´í„° ë¹„ìœ¨

    Returns:
        X_train, y_train, X_test, y_test
    """
    logging.info("ë°ì´í„° ë¡œë“œ ì¤‘...")

    try:
        # ===== ì—¬ê¸°ì— ì‹¤ì œ ë°ì´í„° ë¡œë“œ ë¡œì§ êµ¬í˜„ =====
        # ì˜ˆì‹œ: CSVì—ì„œ ë¡œë“œ
        # df = pd.read_csv(Path(data_path) / 'prepared_data.csv')

        # ì„ì‹œ: ìƒ˜í”Œ ë°ì´í„° ìƒì„±
        logging.warning("ì‹¤ì œ ë°ì´í„°ê°€ ì—†ì–´ ìƒ˜í”Œ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")

        n_samples = 2000
        n_features = 20

        # í”¼ì²˜ ìƒì„±
        X = pd.DataFrame(
            np.random.randn(n_samples, n_features),
            columns=[f'feature_{i}' for i in range(n_features)]
        )

        # íƒ€ê²Ÿ ìƒì„± (ì´ì§„ ë¶„ë¥˜)
        y = pd.Series(np.random.choice([0, 1], n_samples, p=[0.4, 0.6]))

        # Train/Test ë¶„í• 
        split_idx = int(len(X) * train_ratio)

        X_train = X[:split_idx]
        y_train = y[:split_idx]
        X_test = X[split_idx:]
        y_test = y[split_idx:]

        logging.info(f"í•™ìŠµ ë°ì´í„°: {len(X_train):,} samples")
        logging.info(f"í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(X_test):,} samples")
        logging.info(f"í”¼ì²˜ ìˆ˜: {X_train.shape[1]}")

        return X_train, y_train, X_test, y_test

    except Exception as e:
        logging.error(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        return None, None, None, None


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    logging.info("="*60)
    logging.info("ëª¨ë¸ ì„±ëŠ¥ ë¹„êµ ì‹œì‘")
    logging.info("="*60)

    # ===== ë°ì´í„° ë¡œë“œ =====
    X_train, y_train, X_test, y_test = load_train_test_data()

    if X_train is None:
        logging.error("ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨. ì¢…ë£Œí•©ë‹ˆë‹¤.")
        return

    # ===== ModelComparator ì´ˆê¸°í™” =====
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    comparator = ModelComparator(experiment_name=f"model_comparison_{timestamp}")

    # ===== ë¹„êµí•  ëª¨ë¸ë“¤ ì¶”ê°€ =====

    # ëª¨ë¸ 1: XGBoost ê¸°ë³¸ ë²„ì „ (í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ëª¨ë¸)
    logging.info("\nëª¨ë¸ 1: XGBoost v1 (ê¸°ë³¸ íŒŒë¼ë¯¸í„°)")
    model_v1 = XGBoostModel(
        n_estimators=50,
        max_depth=3,
        learning_rate=0.1
    )
    model_v1.build_model({})
    comparator.add_model(
        model_name="XGBoost_v1_baseline",
        model_instance=model_v1,
        description="í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ê¸°ë³¸ ëª¨ë¸",
        hyperparameters={
            'n_estimators': 50,
            'max_depth': 3,
            'learning_rate': 0.1
        }
    )

    # ëª¨ë¸ 2: XGBoost ê°œì„  ë²„ì „
    logging.info("ëª¨ë¸ 2: XGBoost v2 (íŒŒë¼ë¯¸í„° íŠœë‹)")
    model_v2 = XGBoostModel(
        n_estimators=100,
        max_depth=5,
        learning_rate=0.05
    )
    model_v2.build_model({})
    comparator.add_model(
        model_name="XGBoost_v2_tuned",
        model_instance=model_v2,
        description="íŒŒë¼ë¯¸í„° íŠœë‹: ë” ë§ì€ íŠ¸ë¦¬, ë” ê¹Šì€ depth, ë‚®ì€ learning rate",
        hyperparameters={
            'n_estimators': 100,
            'max_depth': 5,
            'learning_rate': 0.05
        }
    )

    # ëª¨ë¸ 3: LightGBM
    logging.info("ëª¨ë¸ 3: LightGBM v1")
    model_v3 = LightGBMModel(
        n_estimators=100,
        max_depth=5,
        learning_rate=0.05
    )
    model_v3.build_model({})
    comparator.add_model(
        model_name="LightGBM_v1",
        model_instance=model_v3,
        description="LightGBM ì•Œê³ ë¦¬ì¦˜ (XGBoost ëŒ€ì²´)",
        hyperparameters={
            'n_estimators': 100,
            'max_depth': 5,
            'learning_rate': 0.05
        }
    )

    # ëª¨ë¸ 4: CatBoost
    logging.info("ëª¨ë¸ 4: CatBoost v1")
    model_v4 = CatBoostModel(
        n_estimators=100,
        max_depth=5,
        learning_rate=0.05
    )
    model_v4.build_model({})
    comparator.add_model(
        model_name="CatBoost_v1",
        model_instance=model_v4,
        description="CatBoost ì•Œê³ ë¦¬ì¦˜",
        hyperparameters={
            'n_estimators': 100,
            'max_depth': 5,
            'learning_rate': 0.05
        }
    )

    # ===== ëª¨ë¸ ë¹„êµ ì‹¤í–‰ =====
    logging.info("\n" + "="*60)
    logging.info("ëª¨ë¸ ë¹„êµ ì‹¤í–‰ ì¤‘...")
    logging.info("="*60)

    comparison_df = comparator.compare_models(
        X_train=X_train,
        y_train=y_train,
        X_test=X_test,
        y_test=y_test,
        cv_splits=3  # 3-fold cross-validation
    )

    # ===== ê°œì„  ì—¬ë¶€ í™•ì¸ =====
    logging.info("\n" + "="*60)
    logging.info("ê°œì„  ì—¬ë¶€ í™•ì¸")
    logging.info("="*60)

    # Baseline(v1) ëŒ€ë¹„ ê° ëª¨ë¸ì˜ ê°œì„  ì—¬ë¶€
    baseline_name = "XGBoost_v1_baseline"

    for model_name in ["XGBoost_v2_tuned", "LightGBM_v1", "CatBoost_v1"]:
        is_improved = comparator.is_improved(
            new_model_name=model_name,
            baseline_model_name=baseline_name,
            metric='accuracy',
            threshold=0.01  # 1% ì´ìƒ ê°œì„ 
        )

    # ===== ê²°ê³¼ ì €ì¥ =====
    output_dir = Path('./results/model_comparison')
    output_dir.mkdir(parents=True, exist_ok=True)

    comparator.save_results(str(output_dir))

    # ì‹œê°í™” (ì„ íƒ ì‚¬í•­)
    try:
        comparator.plot_comparison(str(output_dir / f'comparison_chart_{timestamp}.png'))
    except Exception as e:
        logging.warning(f"ì°¨íŠ¸ ìƒì„± ì‹¤íŒ¨: {str(e)}")

    # ===== ìµœê³  ì„±ëŠ¥ ëª¨ë¸ =====
    best_model_info = comparator.get_best_model()

    if best_model_info:
        logging.info("\n" + "="*60)
        logging.info("ğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸")
        logging.info("="*60)
        logging.info(f"ëª¨ë¸ëª…: {best_model_info['model_name']}")
        logging.info(f"ì„¤ëª…: {best_model_info['description']}")
        logging.info(f"Test Accuracy: {best_model_info['metrics'].get('accuracy', 0):.4f}")
        logging.info(f"F1 Score: {best_model_info['metrics'].get('f1', 0):.4f}")

        # ìµœê³  ëª¨ë¸ ì €ì¥
        best_model_file = Path('./config/best_model.txt')
        best_model_file.parent.mkdir(parents=True, exist_ok=True)
        with open(best_model_file, 'w') as f:
            f.write(f"{best_model_info['model_name']}\n")
            f.write(f"accuracy: {best_model_info['metrics'].get('accuracy', 0):.4f}\n")
            f.write(f"f1: {best_model_info['metrics'].get('f1', 0):.4f}\n")

        logging.info(f"\nâœ… ìµœê³  ëª¨ë¸ ì •ë³´ê°€ {best_model_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    logging.info("\n" + "="*60)
    logging.info("ì™„ë£Œ")
    logging.info("="*60)
    logging.info(f"\nê²°ê³¼ í™•ì¸:")
    logging.info(f"  - {output_dir}")


if __name__ == '__main__':
    # ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
    Path('./logs').mkdir(exist_ok=True)

    main()
