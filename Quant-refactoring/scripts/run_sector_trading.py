"""
ì„¹í„°ë³„ ì‹¤ì „ íŠ¸ë ˆì´ë”© ìŠ¤í¬ë¦½íŠ¸

ì„¹í„°ë³„ë¡œ ë‹¤ë¥¸ í”¼ì²˜ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ì„ í•™ìŠµí•˜ê³ ,
ì „ì²´ì—ì„œ top Nê°œ ì£¼ì‹ì„ ì„ íƒí•©ë‹ˆë‹¤.
"""

import sys
import os

sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '..')))
sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), '../..')))

import pandas as pd
import numpy as np
import logging
from datetime import datetime
from dateutil.relativedelta import relativedelta
from pathlib import Path

from strategy.sector_ensemble import SectorEnsemble, create_default_sector_configs
from models.xgboost_model import XGBoostModel

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('./logs/sector_trading.log'),
        logging.StreamHandler()
    ]
)


def load_data_with_sector(data_path='./VIEW', start_year=2018, end_year=2023):
    """
    ì„¹í„° ì •ë³´ê°€ í¬í•¨ëœ ë°ì´í„° ë¡œë“œ

    Args:
        data_path: ë°ì´í„° ë””ë ‰í† ë¦¬
        start_year: ì‹œì‘ ë…„ë„
        end_year: ì¢…ë£Œ ë…„ë„

    Returns:
        ë°ì´í„°í”„ë ˆì„
    """
    logging.info(f"ë°ì´í„° ë¡œë“œ ì¤‘: {data_path}")

    try:
        # Symbol list (ì„¹í„° ì •ë³´ í¬í•¨)
        symbol_path = Path(data_path) / 'symbol_list.csv'
        if not symbol_path.exists():
            logging.error(f"Symbol list íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {symbol_path}")
            return None

        symbol_df = pd.read_csv(symbol_path)

        # Financial statement ë°ì´í„° ë¡œë“œ
        fs_dfs = []
        for year in range(start_year, end_year + 1):
            fs_path = Path(data_path) / f'financial_statement_{year}.csv'
            if fs_path.exists():
                fs_df = pd.read_csv(fs_path)
                fs_dfs.append(fs_df)
                logging.info(f"  âœ“ {year} ì¬ë¬´ì œí‘œ ë¡œë“œ")

        if not fs_dfs:
            logging.error("ì¬ë¬´ì œí‘œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return None

        # ì¬ë¬´ì œí‘œ í†µí•©
        fs_df = pd.concat(fs_dfs, ignore_index=True)
        fs_df['date'] = pd.to_datetime(fs_df['date'])

        # Symbolê³¼ ì¬ë¬´ì œí‘œ ë³‘í•©
        df = pd.merge(fs_df, symbol_df[['symbol', 'sector']], on='symbol', how='left')

        # ì„¹í„° ì •ë³´ ì—†ëŠ” ê²½ìš° ì œì™¸
        df = df.dropna(subset=['sector'])

        logging.info(f"ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df):,} rows")
        logging.info(f"ì„¹í„° ìˆ˜: {df['sector'].nunique()}")
        logging.info(f"ì„¹í„°ë³„ ë¶„í¬:\n{df['sector'].value_counts()}")

        return df

    except Exception as e:
        logging.error(f"ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {str(e)}")
        import traceback
        traceback.print_exc()
        return None


def prepare_target(df, target_months=3):
    """
    íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„± (ë¯¸ë˜ ìˆ˜ìµë¥ )

    Args:
        df: ë°ì´í„°í”„ë ˆì„
        target_months: ì˜ˆì¸¡ ê¸°ê°„ (ê°œì›”)

    Returns:
        íƒ€ê²Ÿì´ ì¶”ê°€ëœ ë°ì´í„°í”„ë ˆì„
    """
    logging.info(f"íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„± ì¤‘... (ì˜ˆì¸¡ ê¸°ê°„: {target_months}ê°œì›”)")

    df = df.sort_values(['symbol', 'date'])

    # ê° ì£¼ì‹ë³„ë¡œ ë¯¸ë˜ ìˆ˜ìµë¥  ê³„ì‚°
    df['future_price'] = df.groupby('symbol')['close'].shift(-target_months)
    df['future_return'] = (df['future_price'] - df['close']) / df['close'] * 100

    # íƒ€ê²Ÿ: ìˆ˜ìµë¥ ì´ ì–‘ìˆ˜ë©´ 1, ìŒìˆ˜ë©´ 0
    df['target'] = (df['future_return'] > 0).astype(int)

    # ë¯¸ë˜ ë°ì´í„°ê°€ ì—†ëŠ” í–‰ ì œê±°
    df = df.dropna(subset=['future_return'])

    logging.info(f"íƒ€ê²Ÿ ìƒì„± ì™„ë£Œ: {len(df):,} rows")
    logging.info(f"ì–‘ì„± í´ë˜ìŠ¤ ë¹„ìœ¨: {df['target'].mean():.2%}")

    return df


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    logging.info("="*60)
    logging.info("ì„¹í„°ë³„ ì‹¤ì „ íŠ¸ë ˆì´ë”© ì‹œì‘")
    logging.info("="*60)

    # ===== ì„¤ì • =====
    START_YEAR = 2018
    END_YEAR = 2023
    DATA_PATH = './VIEW'  # ì‹¤ì œ ë°ì´í„° ê²½ë¡œ
    TRAIN_YEARS = 3  # í•™ìŠµì— ì‚¬ìš©í•  ê³¼ê±° ë…„ìˆ˜
    TOP_K = 10  # ì„ íƒí•  ì£¼ì‹ ê°œìˆ˜
    REBALANCE_DATE = datetime(2024, 1, 1)  # ë¦¬ë°¸ëŸ°ì‹± ë‚ ì§œ

    # ===== ë°ì´í„° ë¡œë“œ =====
    df = load_data_with_sector(DATA_PATH, START_YEAR, END_YEAR)

    if df is None:
        logging.error("ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨. ì¢…ë£Œí•©ë‹ˆë‹¤.")
        logging.info("\nâš ï¸ ì‹¤ì œ ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš° ìƒ˜í”Œ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸í•˜ë ¤ë©´:")
        logging.info("   python examples/comprehensive_example.py")
        return

    # ===== íƒ€ê²Ÿ ìƒì„± =====
    # ìµœì  ë¦¬ë°¸ëŸ°ì‹± ê¸°ê°„ íŒŒì¼ì´ ìˆìœ¼ë©´ ì‚¬ìš©
    optimal_period_file = Path('./config/optimal_rebalance_period.txt')
    if optimal_period_file.exists():
        with open(optimal_period_file, 'r') as f:
            target_months = int(f.read().strip())
        logging.info(f"ìµœì  ë¦¬ë°¸ëŸ°ì‹± ê¸°ê°„ ì‚¬ìš©: {target_months}ê°œì›”")
    else:
        target_months = 3  # ê¸°ë³¸ê°’
        logging.info(f"ê¸°ë³¸ ë¦¬ë°¸ëŸ°ì‹± ê¸°ê°„ ì‚¬ìš©: {target_months}ê°œì›”")

    df = prepare_target(df, target_months=target_months)

    # ===== í•™ìŠµ/ì˜ˆì¸¡ ë°ì´í„° ë¶„ë¦¬ =====
    train_end = REBALANCE_DATE - relativedelta(days=1)
    train_start = REBALANCE_DATE - relativedelta(years=TRAIN_YEARS)

    train_df = df[(df['date'] >= train_start) & (df['date'] <= train_end)]
    predict_df = df[df['date'] == REBALANCE_DATE]

    if len(predict_df) == 0:
        # ë¦¬ë°¸ëŸ°ì‹± ë‚ ì§œì— ë°ì´í„°ê°€ ì—†ìœ¼ë©´ ê°€ì¥ ìµœê·¼ ë°ì´í„° ì‚¬ìš©
        predict_df = df[df['date'] == df['date'].max()]
        logging.warning(f"ë¦¬ë°¸ëŸ°ì‹± ë‚ ì§œ ë°ì´í„° ì—†ìŒ. ìµœê·¼ ë°ì´í„° ì‚¬ìš©: {predict_df['date'].iloc[0]}")

    logging.info(f"\ní•™ìŠµ ë°ì´í„°: {len(train_df):,} rows ({train_start.strftime('%Y-%m-%d')} ~ {train_end.strftime('%Y-%m-%d')})")
    logging.info(f"ì˜ˆì¸¡ ë°ì´í„°: {len(predict_df):,} rows ({predict_df['date'].iloc[0] if len(predict_df) > 0 else 'N/A'})")

    # ===== SectorEnsemble ì´ˆê¸°í™” =====
    ensemble = SectorEnsemble(sector_col='sector')

    # ê¸°ë³¸ ì„¹í„° ì„¤ì • ì‚¬ìš©
    default_configs = create_default_sector_configs(XGBoostModel)

    # ì‹¤ì œ ë°ì´í„°ì— ìˆëŠ” ì„¹í„°ë§Œ ì„¤ì •
    available_sectors = train_df['sector'].unique()

    for sector_name, config in default_configs.items():
        if sector_name in available_sectors:
            ensemble.configure_sector(
                sector_name=sector_name,
                **config
            )
        else:
            logging.info(f"ì„¹í„° '{sector_name}'ëŠ” ë°ì´í„°ì— ì—†ì–´ ê±´ë„ˆëœë‹ˆë‹¤.")

    # ===== í•™ìŠµ â†’ ì˜ˆì¸¡ â†’ ì„ íƒ =====
    logging.info("\n" + "="*60)
    logging.info("ì„¹í„°ë³„ ëª¨ë¸ í•™ìŠµ ë° ì£¼ì‹ ì„ íƒ")
    logging.info("="*60)

    top_stocks = ensemble.fit_predict_select(
        train_df=train_df,
        predict_df=predict_df,
        target_col='target',
        top_k=TOP_K,
        use_feature_selection=True,
        symbol_col='symbol'
    )

    # ===== ê²°ê³¼ ì¶œë ¥ ë° ì €ì¥ =====
    if top_stocks.empty:
        logging.error("ì„ íƒëœ ì£¼ì‹ì´ ì—†ìŠµë‹ˆë‹¤!")
        return

    logging.info("\n" + "="*60)
    logging.info(f"ğŸ¯ ì„ íƒëœ Top {TOP_K} ì£¼ì‹")
    logging.info("="*60)

    # ìƒì„¸ ì •ë³´ ì¶œë ¥
    for idx, row in top_stocks.iterrows():
        logging.info(f"\n{idx+1}. {row['symbol']}")
        logging.info(f"   ì„¹í„°: {row['sector']}")
        logging.info(f"   ì˜ˆì¸¡ ì ìˆ˜: {row['predicted_score']:.4f}")
        logging.info(f"   ì˜ˆì¸¡ í´ë˜ìŠ¤: {row['predicted_class']}")

    # ì„¹í„°ë³„ ë¶„í¬
    sector_dist = top_stocks['sector'].value_counts()
    logging.info(f"\nì„¹í„°ë³„ ë¶„í¬:")
    for sector, count in sector_dist.items():
        logging.info(f"  {sector}: {count}ê°œ ({count/TOP_K*100:.1f}%)")

    # ===== ê²°ê³¼ ì €ì¥ =====
    output_dir = Path('./results/sector_trading')
    output_dir.mkdir(parents=True, exist_ok=True)

    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')

    # ì„ íƒëœ ì£¼ì‹ ì €ì¥
    output_file = output_dir / f'selected_stocks_{timestamp}.csv'
    top_stocks.to_csv(output_file, index=False)
    logging.info(f"\nğŸ’¾ ì„ íƒëœ ì£¼ì‹ ì €ì¥: {output_file}")

    # ì„¹í„° ì„¤ì • ì €ì¥
    config_file = output_dir / f'sector_config_{timestamp}.json'
    ensemble.save_config(str(config_file))
    logging.info(f"ğŸ’¾ ì„¹í„° ì„¤ì • ì €ì¥: {config_file}")

    # ì„¹í„° ìš”ì•½ ì €ì¥
    sector_summary = ensemble.get_sector_summary()
    summary_file = output_dir / f'sector_summary_{timestamp}.csv'
    sector_summary.to_csv(summary_file, index=False)
    logging.info(f"ğŸ’¾ ì„¹í„° ìš”ì•½ ì €ì¥: {summary_file}")

    # ===== ë§¤ìˆ˜ ì¶”ì²œ ì¶œë ¥ =====
    logging.info("\n" + "="*60)
    logging.info("ğŸ“ˆ ë§¤ìˆ˜ ì¶”ì²œ")
    logging.info("="*60)
    logging.info(f"\në¦¬ë°¸ëŸ°ì‹± ë‚ ì§œ: {REBALANCE_DATE.strftime('%Y-%m-%d')}")
    logging.info(f"ë‹¤ìŒ ë¦¬ë°¸ëŸ°ì‹±: {(REBALANCE_DATE + relativedelta(months=target_months)).strftime('%Y-%m-%d')}")
    logging.info(f"\në§¤ìˆ˜í•  ì£¼ì‹ ({TOP_K}ê°œ):")

    for idx, row in top_stocks.iterrows():
        logging.info(f"  {row['symbol']:<10} (ì„¹í„°: {row['sector']:<15}, ì ìˆ˜: {row['predicted_score']:.4f})")

    logging.info("\n" + "="*60)
    logging.info("ì™„ë£Œ")
    logging.info("="*60)


if __name__ == '__main__':
    # ë¡œê·¸ ë””ë ‰í† ë¦¬ ìƒì„±
    Path('./logs').mkdir(exist_ok=True)

    main()
