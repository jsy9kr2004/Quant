"""
Performance Monitoring System

ëª¨ë¸ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° ì„±ëŠ¥ ì €í•˜ ê°ì§€
"""

import numpy as np
import pandas as pd
import logging
from collections import deque
from scipy import stats
from typing import Dict, List, Optional, Any
import warnings


class PerformanceMonitor:
    """
    ëª¨ë¸ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë° ì„±ëŠ¥ ì €í•˜ ê°ì§€

    ëª¨ë‹ˆí„°ë§ í•­ëª©:
    1. Rolling window ì„±ëŠ¥ ì¶”ì 
    2. ì„±ëŠ¥ ì €í•˜ ì•Œë¦¼ (degradation alert)
    3. ë°ì´í„° drift ê°ì§€
    4. ì¬í•™ìŠµ í•„ìš” ì—¬ë¶€ íŒë‹¨
    """

    def __init__(self,
                 window_size: int = 10,
                 alert_threshold: float = 0.1,
                 drift_threshold: float = 0.05):
        """
        Args:
            window_size: ì„±ëŠ¥ ì¶”ì  ìœˆë„ìš° í¬ê¸°
            alert_threshold: ì„±ëŠ¥ ì €í•˜ ì•Œë¦¼ ì„ê³„ê°’ (10% = 0.1)
            drift_threshold: ë°ì´í„° ë“œë¦¬í”„íŠ¸ p-value ì„ê³„ê°’
        """
        self.window_size = window_size
        self.alert_threshold = alert_threshold
        self.drift_threshold = drift_threshold

        # ì„±ëŠ¥ ì´ë ¥
        self.performance_history = deque(maxlen=window_size)
        self.baseline_performance = None

        # í”¼ì²˜ ë¶„í¬ ì´ë ¥ (drift ê°ì§€ìš©)
        self.feature_distributions = {}

        # ì•Œë¦¼ ì´ë ¥
        self.alerts = []

    def update_performance(self, metrics: Dict[str, float], period_label: Optional[str] = None):
        """
        ì„±ëŠ¥ ì—…ë°ì´íŠ¸ ë° ëª¨ë‹ˆí„°ë§

        Args:
            metrics: ì„±ëŠ¥ ì§€í‘œ ë”•ì…”ë„ˆë¦¬ (ì˜ˆ: {'accuracy': 0.85, 'f1': 0.82})
            period_label: ê¸°ê°„ ë¼ë²¨ (ì˜ˆ: '2023-01')
        """
        performance_record = {
            'period': period_label,
            **metrics
        }

        self.performance_history.append(performance_record)

        # Baseline ì„¤ì • (ìµœì´ˆ 3ê°œ ê¸°ê°„ì˜ í‰ê· )
        if self.baseline_performance is None and len(self.performance_history) >= 3:
            self.baseline_performance = self._calculate_baseline()
            logging.info(f"ğŸ“Š Baseline ì„±ëŠ¥ ì„¤ì •ë¨:")
            for metric, value in self.baseline_performance.items():
                logging.info(f"   {metric}: {value:.4f}")

        # ì„±ëŠ¥ ì €í•˜ ì²´í¬
        if self.baseline_performance is not None:
            alerts = self._check_performance_degradation(metrics, period_label)
            if alerts:
                self.alerts.extend(alerts)

    def _calculate_baseline(self) -> Dict[str, float]:
        """ì´ˆê¸° ì„±ëŠ¥ ê¸°ì¤€ì„  ê³„ì‚° (ìµœì´ˆ 3ê°œ ê¸°ê°„ì˜ í‰ê· )"""
        history = list(self.performance_history)[:3]
        baseline = {}

        # ëª¨ë“  metricì˜ í‰ê·  ê³„ì‚°
        for metric in history[0].keys():
            if metric != 'period':
                values = [h[metric] for h in history if metric in h]
                if values:
                    baseline[metric] = np.mean(values)

        return baseline

    def _check_performance_degradation(self,
                                      current_metrics: Dict[str, float],
                                      period_label: Optional[str] = None) -> List[Dict]:
        """
        ì„±ëŠ¥ ì €í•˜ ê°ì§€

        Args:
            current_metrics: í˜„ì¬ ì„±ëŠ¥ ì§€í‘œ
            period_label: ê¸°ê°„ ë¼ë²¨

        Returns:
            ì•Œë¦¼ ë¦¬ìŠ¤íŠ¸
        """
        alerts = []

        for metric, baseline_value in self.baseline_performance.items():
            if metric == 'period':
                continue

            current_value = current_metrics.get(metric, 0)

            # ì„±ëŠ¥ í•˜ë½ë¥  ê³„ì‚°
            if baseline_value != 0:
                degradation = (baseline_value - current_value) / baseline_value
            else:
                degradation = 0

            if degradation > self.alert_threshold:
                alert_msg = (
                    f"âš ï¸ ì„±ëŠ¥ ì €í•˜ ê°ì§€!\n"
                    f"   Period: {period_label}\n"
                    f"   Metric: {metric}\n"
                    f"   Baseline: {baseline_value:.4f}\n"
                    f"   Current:  {current_value:.4f}\n"
                    f"   ì €í•˜ìœ¨: {degradation*100:.2f}%"
                )
                logging.warning(alert_msg)

                alert = {
                    'period': period_label,
                    'metric': metric,
                    'baseline': baseline_value,
                    'current': current_value,
                    'degradation': degradation
                }
                alerts.append(alert)

        return alerts

    def check_feature_drift(self,
                           X_new: np.ndarray,
                           feature_names: List[str],
                           reference_X: Optional[np.ndarray] = None) -> List[Dict]:
        """
        í”¼ì²˜ ë¶„í¬ ë³€í™” ê°ì§€ (Data Drift)

        Kolmogorov-Smirnov test ì‚¬ìš©í•˜ì—¬ ë¶„í¬ ë³€í™” ê°ì§€

        Args:
            X_new: ìƒˆë¡œìš´ í”¼ì²˜ ë°ì´í„°
            feature_names: í”¼ì²˜ ì´ë¦„ ë¦¬ìŠ¤íŠ¸
            reference_X: ê¸°ì¤€ í”¼ì²˜ ë°ì´í„° (Noneì´ë©´ X_newë¥¼ ê¸°ì¤€ìœ¼ë¡œ ì €ì¥)

        Returns:
            ë“œë¦¬í”„íŠ¸ê°€ ê°ì§€ëœ í”¼ì²˜ ì •ë³´ ë¦¬ìŠ¤íŠ¸
        """
        if reference_X is None and not self.feature_distributions:
            # ì²« ì‹¤í–‰: ê¸°ì¤€ ë¶„í¬ ì €ì¥
            for i, feat in enumerate(feature_names):
                if i < X_new.shape[1]:
                    self.feature_distributions[feat] = X_new[:, i]
            logging.info(f"ğŸ“Š ê¸°ì¤€ í”¼ì²˜ ë¶„í¬ ì €ì¥ ì™„ë£Œ ({len(feature_names)}ê°œ í”¼ì²˜)")
            return []

        drift_features = []

        for i, feat in enumerate(feature_names):
            if i >= X_new.shape[1]:
                continue

            if feat not in self.feature_distributions:
                # ìƒˆë¡œìš´ í”¼ì²˜ëŠ” ë¶„í¬ ì €ì¥
                self.feature_distributions[feat] = X_new[:, i]
                continue

            try:
                # KS test (ë‘ ë¶„í¬ ë¹„êµ)
                with warnings.catch_warnings():
                    warnings.simplefilter("ignore")
                    statistic, p_value = stats.ks_2samp(
                        self.feature_distributions[feat],
                        X_new[:, i]
                    )

                if p_value < self.drift_threshold:
                    logging.warning(
                        f"âš ï¸ í”¼ì²˜ ë“œë¦¬í”„íŠ¸ ê°ì§€: {feat}\n"
                        f"   KS statistic: {statistic:.4f}, p-value: {p_value:.4f}"
                    )
                    drift_features.append({
                        'feature': feat,
                        'ks_statistic': statistic,
                        'p_value': p_value
                    })

            except Exception as e:
                logging.debug(f"KS test failed for {feat}: {str(e)}")
                continue

        if drift_features:
            logging.warning(f"ì´ {len(drift_features)}ê°œ í”¼ì²˜ì—ì„œ ë“œë¦¬í”„íŠ¸ ê°ì§€ë¨")

        return drift_features

    def should_retrain(self, consecutive_periods: int = 3) -> bool:
        """
        ì¬í•™ìŠµ í•„ìš” ì—¬ë¶€ íŒë‹¨

        ìµœê·¼ Nê°œ ê¸°ê°„ ëª¨ë‘ baselineë³´ë‹¤ ì„±ëŠ¥ì´ ë‚®ìœ¼ë©´ ì¬í•™ìŠµ ê¶Œì¥

        Args:
            consecutive_periods: ì—°ì†ìœ¼ë¡œ ì²´í¬í•  ê¸°ê°„ ìˆ˜

        Returns:
            ì¬í•™ìŠµ í•„ìš” ì—¬ë¶€
        """
        if len(self.performance_history) < consecutive_periods:
            return False

        if self.baseline_performance is None:
            return False

        recent = list(self.performance_history)[-consecutive_periods:]

        # ì£¼ìš” ì§€í‘œ ì„ íƒ (accuracy or f1 or rmse)
        metric = None
        if 'accuracy' in self.baseline_performance:
            metric = 'accuracy'
        elif 'f1' in self.baseline_performance:
            metric = 'f1'
        elif 'rmse' in self.baseline_performance:
            metric = 'rmse'
        else:
            # ì²« ë²ˆì§¸ metric ì‚¬ìš©
            metric = list(self.baseline_performance.keys())[0]

        if metric not in self.baseline_performance:
            return False

        baseline_value = self.baseline_performance[metric]

        # ìµœê·¼ Nê°œ ê¸°ê°„ì˜ metric ê°’ ì¶”ì¶œ
        recent_values = []
        for r in recent:
            if metric in r:
                recent_values.append(r[metric])

        if len(recent_values) < consecutive_periods:
            return False

        # rmseëŠ” ë‚®ì„ìˆ˜ë¡ ì¢‹ìŒ
        if metric == 'rmse':
            all_degraded = all(v > baseline_value * (1 + self.alert_threshold)
                              for v in recent_values)
        else:
            # accuracy, f1 ë“±ì€ ë†’ì„ìˆ˜ë¡ ì¢‹ìŒ
            all_degraded = all(v < baseline_value * (1 - self.alert_threshold)
                              for v in recent_values)

        if all_degraded:
            logging.warning(
                f"ğŸ”„ ì¬í•™ìŠµ ê¶Œì¥!\n"
                f"   ìµœê·¼ {consecutive_periods}ê°œ ê¸°ê°„ ëª¨ë‘ baseline ëŒ€ë¹„ "
                f"{self.alert_threshold*100}% ì´ìƒ ë³€í™”\n"
                f"   Metric: {metric}\n"
                f"   Baseline: {baseline_value:.4f}\n"
                f"   Recent: {[f'{v:.4f}' for v in recent_values]}"
            )
            return True

        return False

    def get_performance_summary(self) -> Dict[str, Any]:
        """
        ì„±ëŠ¥ ìš”ì•½ ë¦¬í¬íŠ¸

        Returns:
            ì„±ëŠ¥ ìš”ì•½ ë”•ì…”ë„ˆë¦¬
        """
        if not self.performance_history:
            return {"status": "ì„±ëŠ¥ ì´ë ¥ ì—†ìŒ"}

        df = pd.DataFrame(list(self.performance_history))

        # 'period' ì»¬ëŸ¼ ì œì™¸í•˜ê³  í†µê³„ ê³„ì‚°
        numeric_cols = [col for col in df.columns if col != 'period']

        summary = {
            'baseline': self.baseline_performance,
            'current': dict(df.iloc[-1]),
            'window_size': len(self.performance_history),
            'statistics': {}
        }

        for col in numeric_cols:
            summary['statistics'][col] = {
                'mean': df[col].mean(),
                'std': df[col].std(),
                'min': df[col].min(),
                'max': df[col].max(),
                'current': df[col].iloc[-1]
            }

        # ì•Œë¦¼ ìš”ì•½
        summary['total_alerts'] = len(self.alerts)
        summary['recent_alerts'] = len([a for a in self.alerts
                                       if a.get('period') == df.iloc[-1].get('period')])

        return summary

    def print_summary(self):
        """ì„±ëŠ¥ ìš”ì•½ ì¶œë ¥"""
        summary = self.get_performance_summary()

        if summary.get('status'):
            logging.info(summary['status'])
            return

        logging.info(f"\n{'='*60}")
        logging.info("ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ìš”ì•½")
        logging.info(f"{'='*60}")

        if summary.get('baseline'):
            logging.info("\nğŸ“Š Baseline ì„±ëŠ¥:")
            for metric, value in summary['baseline'].items():
                logging.info(f"   {metric}: {value:.4f}")

        logging.info(f"\nğŸ“ˆ í†µê³„ (ìµœê·¼ {summary['window_size']}ê°œ ê¸°ê°„):")
        for metric, stats in summary['statistics'].items():
            logging.info(f"   {metric}:")
            logging.info(f"      Mean: {stats['mean']:.4f} (Â±{stats['std']:.4f})")
            logging.info(f"      Range: [{stats['min']:.4f}, {stats['max']:.4f}]")
            logging.info(f"      Current: {stats['current']:.4f}")

        logging.info(f"\nâš ï¸ ì•Œë¦¼:")
        logging.info(f"   ì´ ì•Œë¦¼: {summary['total_alerts']}")
        logging.info(f"   ìµœê·¼ ì•Œë¦¼: {summary['recent_alerts']}")

        logging.info(f"\n{'='*60}\n")

    def reset(self):
        """ëª¨ë‹ˆí„°ë§ ìƒíƒœ ì´ˆê¸°í™”"""
        self.performance_history.clear()
        self.baseline_performance = None
        self.feature_distributions.clear()
        self.alerts.clear()
        logging.info("âœ… ì„±ëŠ¥ ëª¨ë‹ˆí„° ì´ˆê¸°í™” ì™„ë£Œ")

    def get_alerts_dataframe(self) -> pd.DataFrame:
        """ì•Œë¦¼ ì´ë ¥ì„ ë°ì´í„°í”„ë ˆì„ìœ¼ë¡œ ë°˜í™˜"""
        if not self.alerts:
            return pd.DataFrame()
        return pd.DataFrame(self.alerts)
