# Quant Trading System - ê°œë°œì ì›Œí¬í”Œë¡œìš° ê°€ì´ë“œ

> **ëª©ì **: ìƒˆë¡œìš´ ê°œë°œì ì˜¨ë³´ë”© ë° ì½”ë“œ ë¦¬ë·°ë¥¼ ìœ„í•œ ì¢…í•© ê°€ì´ë“œ
> **ì‘ì„±ì¼**: 2025-10-27
> **ëŒ€ìƒ**: ì‹ ê·œ ê°œë°œì, íˆ¬ììë¥¼ ìœ„í•œ ê¸°ìˆ  ë¦¬ë·°

---

## ğŸ“‹ ëª©ì°¨

1. [í”„ë¡œì íŠ¸ ê°œìš”](#-í”„ë¡œì íŠ¸-ê°œìš”)
2. [ì „ì²´ ì•„í‚¤í…ì²˜](#-ì „ì²´-ì•„í‚¤í…ì²˜)
3. [ë°ì´í„° íŒŒì´í”„ë¼ì¸](#-ë°ì´í„°-íŒŒì´í”„ë¼ì¸)
4. [AI ëª¨ë¸ ìƒì„¸](#-ai-ëª¨ë¸-ìƒì„¸)
5. [ì£¼ìš” ì»´í¬ë„ŒíŠ¸](#-ì£¼ìš”-ì»´í¬ë„ŒíŠ¸)
6. [ì‹¤í–‰ í”Œë¡œìš°](#-ì‹¤í–‰-í”Œë¡œìš°)
7. [í˜„ì¬ í•œê³„ì  ë° ê°œì„  ë°©í–¥](#-í˜„ì¬-í•œê³„ì -ë°-ê°œì„ -ë°©í–¥)

---

## ğŸ¯ í”„ë¡œì íŠ¸ ê°œìš”

### ì‹œìŠ¤í…œ ëª©ì 
ì£¼ì‹ ì‹œì¥ì—ì„œ **ìš°ìˆ˜í•œ ì„±ê³¼ë¥¼ ë‚¼ ê²ƒìœ¼ë¡œ ì˜ˆì¸¡ë˜ëŠ” ì¢…ëª©ì„ ìë™ìœ¼ë¡œ ì„ ë³„**í•˜ëŠ” Quantitative Trading ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

### í•µì‹¬ ê¸°ëŠ¥
- **ë°ì´í„° ìˆ˜ì§‘**: Financial Modeling Prep (FMP) APIë¥¼ í†µí•œ ì¬ë¬´ì œí‘œ, ê°€ê²© ë°ì´í„° ìˆ˜ì§‘
- **íŠ¹ì„± ì—”ì§€ë‹ˆì–´ë§**: ì¬ë¬´ ë¹„ìœ¨ + ì‹œê³„ì—´ íŠ¹ì„± ì¶”ì¶œ (tsfresh)
- **ë¨¸ì‹ ëŸ¬ë‹ ì˜ˆì¸¡**: XGBoost + LightGBM + CatBoost ì•™ìƒë¸” ëª¨ë¸
- **ë°±í…ŒìŠ¤íŒ…**: ê³¼ê±° ë°ì´í„° ê¸°ë°˜ ì „ëµ ì„±ê³¼ ê²€ì¦
- **ìë™í™”**: ë°ì´í„° ìˆ˜ì§‘ â†’ í•™ìŠµ â†’ ì˜ˆì¸¡ â†’ ë°±í…ŒìŠ¤íŒ… ì „ ê³¼ì • ìë™í™”

### ê¸°ìˆ  ìŠ¤íƒ
```
ì–¸ì–´: Python 3.8+
ML í”„ë ˆì„ì›Œí¬: XGBoost, LightGBM, CatBoost, scikit-learn
ë°ì´í„° ì²˜ë¦¬: Pandas, NumPy, PyArrow (Parquet)
íŠ¹ì„± ì¶”ì¶œ: tsfresh (ì‹œê³„ì—´ íŠ¹ì„±)
ì‹¤í—˜ ì¶”ì : MLflow
ìµœì í™”: Optuna
ë°ì´í„° ì†ŒìŠ¤: FMP API
```

---

## ğŸ— ì „ì²´ ì•„í‚¤í…ì²˜

### ì‹œìŠ¤í…œ í”Œë¡œìš° ë‹¤ì´ì–´ê·¸ë¨

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    1. Configuration Loading                      â”‚
â”‚                    (config/conf.yaml)                            â”‚
â”‚         â”œâ”€ DATA: API Keys, Paths, Years                         â”‚
â”‚         â”œâ”€ ML: Model settings, MLflow config                    â”‚
â”‚         â””â”€ BACKTEST: Strategy parameters                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              2. Data Collection (Optional, GET_FMP=Y)            â”‚
â”‚                                                                  â”‚
â”‚  [FMP API] â†’ data_collector/fmp.py                              â”‚
â”‚     â”œâ”€ Stock List (NASDAQ, NYSE)                                â”‚
â”‚     â”œâ”€ Delisted Companies                                       â”‚
â”‚     â”œâ”€ Financial Statements (Income, Balance, CashFlow)         â”‚
â”‚     â”œâ”€ Key Metrics (P/E, ROE, Debt Ratios...)                   â”‚
â”‚     â””â”€ Historical Price Data                                    â”‚
â”‚            â†“                                                     â”‚
â”‚     CSV Files â†’ /data/{category}/{symbol}.csv                   â”‚
â”‚            â†“                                                     â”‚
â”‚  storage/parquet_converter.py                                   â”‚
â”‚     â†’ Parquet Files (5-10x faster, 85-90% compressed)           â”‚
â”‚            â†“                                                     â”‚
â”‚     /data/VIEW/ (í†µí•© ë·°)                                         â”‚
â”‚       â”œâ”€ symbol_list.csv                                        â”‚
â”‚       â”œâ”€ price.csv                                              â”‚
â”‚       â”œâ”€ financial_statement_{year}.csv                         â”‚
â”‚       â””â”€ metrics_{year}.csv                                     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚           3. ML Data Preparation (training/make_mldata.py)       â”‚
â”‚                                                                  â”‚
â”‚  VIEW ë°ì´í„° ë¡œë“œ â†’ Merge (symbol, date ê¸°ì¤€)                    â”‚
â”‚            â†“                                                     â”‚
â”‚  ì‹œê³„ì—´ ìœˆë„ìš° ìƒì„± (12ê°œì›” lookback)                              â”‚
â”‚            â†“                                                     â”‚
â”‚  tsfresh íŠ¹ì„± ì¶”ì¶œ (EfficientFCParameters)                       â”‚
â”‚    â”œâ”€ standard_deviation                                        â”‚
â”‚    â”œâ”€ quantile                                                  â”‚
â”‚    â”œâ”€ autocorrelation                                           â”‚
â”‚    â”œâ”€ fft_coefficient                                           â”‚
â”‚    â””â”€ ar_coefficient (36ê°œ ì‹œê³„ì—´ íŠ¹ì„±)                          â”‚
â”‚            â†“                                                     â”‚
â”‚  ì¬ë¬´ ë¹„ìœ¨ ê³„ì‚° (139ê°œ ratio features)                            â”‚
â”‚    â”œâ”€ ROE, ROIC, Profit Margins                                â”‚
â”‚    â”œâ”€ P/E, P/B, EV/EBITDA                                       â”‚
â”‚    â”œâ”€ Debt Ratios, Coverage Ratios                             â”‚
â”‚    â””â”€ Customized: OverMC_*, adaptiveMC_*                       â”‚
â”‚            â†“                                                     â”‚
â”‚  RobustScaler ì •ê·œí™” (Outlier-resistant)                         â”‚
â”‚            â†“                                                     â”‚
â”‚  Target ë³€ìˆ˜ ìƒì„±: price_dev, price_dev_subavg                  â”‚
â”‚            â†“                                                     â”‚
â”‚  /data/ml_per_year/rnorm_ml_{year}_{quarter}.parquet           â”‚
â”‚    (ì˜ˆ: rnorm_ml_2015_Q1.parquet, rnorm_ml_2015_Q2.parquet...) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              4. Model Training (training/regressor.py)           â”‚
â”‚                                                                  â”‚
â”‚  ë°ì´í„° ë¡œë“œ (2015-2021 í•™ìŠµ, 2022-2023 í…ŒìŠ¤íŠ¸)                   â”‚
â”‚            â†“                                                     â”‚
â”‚  ë°ì´í„° í´ë¦¬ë‹                                                    â”‚
â”‚    â”œâ”€ 80% ì´ìƒ ê²°ì¸¡ì¹˜ ì»¬ëŸ¼ ì œê±°                                   â”‚
â”‚    â”œâ”€ 95% ì´ìƒ ë™ì¼ ê°’ ì»¬ëŸ¼ ì œê±°                                  â”‚
â”‚    â””â”€ 60% ì´ìƒ ê²°ì¸¡ì¹˜ í–‰ ì œê±°                                     â”‚
â”‚            â†“                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚         Classification Models (Binary)          â”‚            â”‚
â”‚  â”‚  (ìƒìŠ¹/í•˜ë½ ì˜ˆì¸¡ â†’ í•„í„°ë§ ìš©ë„)                   â”‚            â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤            â”‚
â”‚  â”‚  clsmodel_0: XGBoost Classifier (depth=8)      â”‚            â”‚
â”‚  â”‚  clsmodel_1: XGBoost Classifier (depth=9)      â”‚            â”‚
â”‚  â”‚  clsmodel_2: XGBoost Classifier (depth=10)     â”‚            â”‚
â”‚  â”‚  clsmodel_3: LightGBM Classifier (depth=8)     â”‚            â”‚
â”‚  â”‚                                                 â”‚            â”‚
â”‚  â”‚  â†’ Ensemble Voting (ìƒìœ„ 92% threshold)        â”‚            â”‚
â”‚  â”‚  â†’ Binary Filter: ìƒìŠ¹ ì˜ˆìƒ ì¢…ëª©ë§Œ ì„ íƒ           â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚            â†“                                                     â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”            â”‚
â”‚  â”‚         Regression Models (Continuous)          â”‚            â”‚
â”‚  â”‚  (ìƒìŠ¹í­ ì˜ˆì¸¡ â†’ ë­í‚¹ ìš©ë„)                         â”‚            â”‚
â”‚  â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤            â”‚
â”‚  â”‚  model_0: XGBoost Regressor (depth=8)          â”‚            â”‚
â”‚  â”‚  model_1: XGBoost Regressor (depth=10)         â”‚            â”‚
â”‚  â”‚                                                 â”‚            â”‚
â”‚  â”‚  â†’ Average Prediction                          â”‚            â”‚
â”‚  â”‚  â†’ ìƒìŠ¹í­ í° ìˆœì„œë¡œ ì¢…ëª© ë­í‚¹                      â”‚            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”‚
â”‚            â†“                                                     â”‚
â”‚  Final Prediction Strategy:                                     â”‚
â”‚    1. Classification ëª¨ë¸ë¡œ í•„í„°ë§ (ìƒìŠ¹ ì˜ˆìƒ ì¢…ëª©ë§Œ)              â”‚
â”‚    2. Regression ëª¨ë¸ë¡œ ìƒìŠ¹í­ ì˜ˆì¸¡                               â”‚
â”‚    3. ì˜ˆì¸¡ê°’ ë†’ì€ ìˆœìœ¼ë¡œ Top-K ì¢…ëª© ì„ ì •                          â”‚
â”‚            â†“                                                     â”‚
â”‚  Model ì €ì¥: /data/MODELS/                                       â”‚
â”‚    â”œâ”€ clsmodel_{0,1,2,3}.sav                                    â”‚
â”‚    â””â”€ model_{0,1}.sav                                           â”‚
â”‚            â†“                                                     â”‚
â”‚  Optional: MLflow ì‹¤í—˜ ì¶”ì                                        â”‚
â”‚    â”œâ”€ í•˜ì´í¼íŒŒë¼ë¯¸í„° ë¡œê¹…                                          â”‚
â”‚    â”œâ”€ ë©”íŠ¸ë¦­ ë¡œê¹… (Accuracy, RMSE)                               â”‚
â”‚    â””â”€ ëª¨ë¸ ì•„í‹°íŒ©íŠ¸ ì €ì¥                                           â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚          5. Evaluation (training/regressor.py:evaluation())      â”‚
â”‚                                                                  â”‚
â”‚  Test Set ê° ë¶„ê¸°ë³„ í‰ê°€                                          â”‚
â”‚    â”œâ”€ Classification Accuracy (threshold=92%)                  â”‚
â”‚    â”œâ”€ Regression RMSE                                          â”‚
â”‚    â””â”€ Top-K ì¢…ëª©ì˜ ì‹¤ì œ ìˆ˜ìµë¥  ê³„ì‚°                               â”‚
â”‚            â†“                                                     â”‚
â”‚  ì˜ˆì¸¡ ê²°ê³¼ ì €ì¥                                                   â”‚
â”‚    â”œâ”€ prediction_ai_{year}_{quarter}.csv (ì „ì²´ ì˜ˆì¸¡)            â”‚
â”‚    â”œâ”€ prediction_ai_{year}_{quarter}_{model}_top0-3.csv        â”‚
â”‚    â”œâ”€ prediction_ai_{year}_{quarter}_{model}_top0-7.csv        â”‚
â”‚    â””â”€ pred_df_topk.csv (ìš”ì•½ í†µê³„)                              â”‚
â”‚            â†“                                                     â”‚
â”‚  Latest Prediction (ìµœì‹  ë°ì´í„° ì˜ˆì¸¡)                             â”‚
â”‚    â†’ latest_prediction.csv                                      â”‚
â”‚    â†’ latest_prediction_{model}_top0-3.csv                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                             â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚               6. Backtesting (backtest.py) - Optional            â”‚
â”‚                                                                  â”‚
â”‚  plan.csv ì „ëµ ë¡œë“œ                                               â”‚
â”‚    (key, key_dir, weight, diff, base, base_dir)                â”‚
â”‚            â†“                                                     â”‚
â”‚  For each rebalancing date:                                     â”‚
â”‚    1. Load ì¬ë¬´ ë°ì´í„° snapshot                                  â”‚
â”‚    2. Calculate scores (plan ê¸°ì¤€)                              â”‚
â”‚    3. Select Top-K stocks                                       â”‚
â”‚    4. Record entry prices                                       â”‚
â”‚    5. Wait until next rebalance                                 â”‚
â”‚    6. Record exit prices                                        â”‚
â”‚    7. Calculate returns                                         â”‚
â”‚            â†“                                                     â”‚
â”‚  Generate Reports:                                              â”‚
â”‚    â”œâ”€ EVAL: ê° ë¦¬ë°¸ëŸ°ì‹± ê¸°ê°„ë³„ ìƒì„¸ ë©”íŠ¸ë¦­                         â”‚
â”‚    â”œâ”€ RANK: ì¢…ëª© ë­í‚¹                                            â”‚
â”‚    â””â”€ AVG: ìš”ì•½ í†µê³„ (Sharpe, Max DD, Win Rate...)              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š ë°ì´í„° íŒŒì´í”„ë¼ì¸

### 1. FMP API ë°ì´í„° ìˆ˜ì§‘
**íŒŒì¼**: `data_collector/fmp.py`

```python
# ì£¼ìš” íë¦„
FMP.__get_api_list()           # target_api_list.csv ì½ê¸°
  â†“
FMP.__fetch_ticker_list()      # stock_list, delisted_companies
  â†“
FMP.__set_symbol()              # NASDAQ, NYSE í•„í„°ë§ â†’ symbol_list
  â†“
FMP.__fetch_data()              # ë‚˜ë¨¸ì§€ ë°ì´í„° (FS, metrics, price)
  â†“
CSV Files saved to /data/{category}/
```

**ìˆ˜ì§‘ ë°ì´í„°**:
- `stock_list`: ìƒì¥ ì¢…ëª© ë¦¬ìŠ¤íŠ¸ (symbol, sector, industry, ipoDate)
- `delisted_companies`: ìƒì¥íì§€ ì¢…ëª©
- `income_statement`: ì†ìµê³„ì‚°ì„œ
- `balance_sheet_statement`: ì¬ë¬´ìƒíƒœí‘œ
- `cash_flow_statement`: í˜„ê¸ˆíë¦„í‘œ
- `key_metrics`: í•µì‹¬ ì¬ë¬´ë¹„ìœ¨ (P/E, ROE, Debt/Equity...)
- `financial_growth`: ì„±ì¥ë¥  ì§€í‘œ
- `historical_price_full`: ì¼ë³„ ê°€ê²© ë°ì´í„°

**íŠ¹ì§•**:
- **Multiprocessing**: `fmp_fetch_worker.py`ì—ì„œ ë³‘ë ¬ ë‹¤ìš´ë¡œë“œ
- **Filtering**: NASDAQ, NYSEë§Œ ìˆ˜ì§‘ (ë¯¸êµ­ ì£¼ìš” ê±°ë˜ì†Œ)
- **Update Check**: `config/update_date.txt`ë¡œ ì¤‘ë³µ ìˆ˜ì§‘ ë°©ì§€

### 2. Parquet ë³€í™˜ ë° VIEW ìƒì„±
**íŒŒì¼**: `storage/parquet_converter.py`

```python
# CSV â†’ Parquet ë³€í™˜
ParquetConverter.insert_csv()
  â†“
ì••ì¶•ë¥ : 85-90%
ì½ê¸° ì†ë„: CSV ëŒ€ë¹„ 5-10ë°° ë¹ ë¦„
  â†“
ParquetConverter.rebuild_table_view()
  â†’ VIEW/symbol_list.parquet
  â†’ VIEW/price.parquet
  â†’ VIEW/financial_statement_{year}.parquet
  â†’ VIEW/metrics_{year}.parquet
  (ì„ íƒì‚¬í•­: SAVE_DEBUG_CSV=Yì¼ ë•Œ .csv íŒŒì¼ë„ í•¨ê»˜ ìƒì„±)
```

**VIEWì˜ ì—­í• **: ì—¬ëŸ¬ Parquet íŒŒì¼ì„ í†µí•©í•˜ì—¬ ML í•™ìŠµì— ë°”ë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ í˜•íƒœë¡œ ì¬êµ¬ì„±

### 3. ML ë°ì´í„° ìƒì„±
**íŒŒì¼**: `training/make_mldata.py`

#### 3-1. ë°ì´í„° ë¡œë“œ
```python
AIDataMaker.load_bt_table()
  - symbol_table: ì¢…ëª© ì •ë³´
  - price_table: ê°€ê²© ë°ì´í„°
  - fs_table: ì¬ë¬´ì œí‘œ (3ë…„ ì „~í˜„ì¬)
  - metrics_table: ì¬ë¬´ë¹„ìœ¨
```

#### 3-2. ë¦¬ë°¸ëŸ°ì‹± ë‚ ì§œ ì„¤ì •
```python
AIDataMaker.set_date()
  - REBALANCE_PERIOD: 3ê°œì›” (ë¶„ê¸°ë³„)
  - ì‹œì‘: start_year-3
  - ì¢…ë£Œ: end_year
  â†’ trade_date_list (ì‹¤ì œ ê±°ë˜ì¼ë¡œ ë³´ì •)
```

#### 3-3. ê°€ê²© ë³€í™”ëŸ‰ ê³„ì‚°
```python
AIDataMaker.process_price_table_wdate()
  - price_diff: ë‹¤ìŒ ê¸°ê°„ ê°€ê²© ë³€í™” (ì ˆëŒ€ê°’)
  - price_dev: ê°€ê²© ë³€í™”ìœ¨ (ìˆ˜ìµë¥ ) â†’ Target ë³€ìˆ˜
  - price_dev_subavg: í‰ê·  ëŒ€ë¹„ ì´ˆê³¼ ìˆ˜ìµë¥ 
```

#### 3-4. ì‹œê³„ì—´ íŠ¹ì„± ì¶”ì¶œ
```python
AIDataMaker.make_ml_data()
  For each year, quarter:
    1. 12ê°œì›” lookback window ìƒì„±
    2. tsfresh.extract_features()
       - EfficientFCParameters ì‚¬ìš©
       - 36ê°œ ì‹œê³„ì—´ íŠ¹ì„± ì¶”ì¶œ
    3. ì¬ë¬´ ë¹„ìœ¨ ê³„ì‚° (139ê°œ)
       - ratio_col_list: ê¸°ë³¸ ë¹„ìœ¨
       - OverMC_*: ì‹œì´ ëŒ€ë¹„ ë¹„ìœ¨
       - adaptiveMC_*: EV ëŒ€ë¹„ ë¹„ìœ¨
    4. RobustScaler ì •ê·œí™”
       - Outlierì— ê°•ê±´í•œ ì •ê·œí™”
       - Median, IQR ê¸°ë°˜
    5. Sector ì •ë³´ ì¶”ê°€
       - industry â†’ sector mapping
       - sec_price_dev_subavg: ì„¹í„° ëŒ€ë¹„ ì´ˆê³¼ ìˆ˜ìµë¥ 
    6. Parquet ì €ì¥
       â†’ rnorm_ml_{year}_{quarter}.parquet
```

**tsfresh íŠ¹ì„± ìƒì„¸**:
```python
suffixes_dict = {
    "standard_deviation": ["__r_0.0", "__r_0.25", "__r_0.6", "__r_0.9"],
    "quantile": ["__q_0.2", "__q_0.8"],
    "autocorrelation": ["__lag_0", "__lag_5", "__lag_9"],
    "fft_coefficient": ["__coeff_0", "__coeff_33", "__coeff_99"],
    "cwt_coefficients": ["__coeff_0", "__coeff_6", "__coeff_12"],
    "symmetry_looking": ["__r_0.0", "__r_0.25", "__r_0.65", "__r_0.9"],
    "ar_coefficient": ["__coeff_0", "__coeff_3", "__coeff_6", "__coeff_10"]
}
```
â†’ Feature ì°¨ì› ì¶•ì†Œ: ëª¨ë“  íŠ¹ì„± ëŒ€ì‹  ì£¼ìš” Suffixë§Œ ì„ íƒ

---

## ğŸ¤– AI ëª¨ë¸ ìƒì„¸

### ëª¨ë¸ ì•„í‚¤í…ì²˜ ê°œìš”

#### ë‘ ë‹¨ê³„ ì˜ˆì¸¡ ì „ëµ (Two-Stage Prediction)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Stage 1: Classification                      â”‚
â”‚            "ìƒìŠ¹í•  ì¢…ëª© vs í•˜ë½í•  ì¢…ëª©"                         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Input: 350+ features (ì¬ë¬´ë¹„ìœ¨ + ì‹œê³„ì—´ íŠ¹ì„±)                 â”‚
â”‚  Target: price_dev > 0 â†’ 1 (ìƒìŠ¹), else â†’ 0 (í•˜ë½)           â”‚
â”‚                                                             â”‚
â”‚  Models:                                                    â”‚
â”‚    1. XGBoost Classifier (depth=8)                         â”‚
â”‚    2. XGBoost Classifier (depth=9)                         â”‚
â”‚    3. XGBoost Classifier (depth=10)                        â”‚
â”‚    4. LightGBM Classifier (depth=8)                        â”‚
â”‚                                                             â”‚
â”‚  Ensemble: Voting (majority vote)                          â”‚
â”‚  Threshold: ìƒìœ„ 92% (aggressive filtering)                â”‚
â”‚                                                             â”‚
â”‚  Output: Binary mask (ìƒìŠ¹ ì˜ˆìƒ ì¢…ëª©ë§Œ True)                  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Stage 2: Regression                         â”‚
â”‚              "ì–¼ë§ˆë‚˜ ìƒìŠ¹í•  ê²ƒì¸ê°€?"                            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Input: Stage 1ì—ì„œ í•„í„°ë§ëœ ì¢…ëª©ë§Œ                            â”‚
â”‚  Target: price_dev_subavg (í‰ê·  ëŒ€ë¹„ ì´ˆê³¼ ìˆ˜ìµë¥ )             â”‚
â”‚                                                             â”‚
â”‚  Models:                                                    â”‚
â”‚    1. XGBoost Regressor (depth=8)                          â”‚
â”‚    2. XGBoost Regressor (depth=10)                         â”‚
â”‚                                                             â”‚
â”‚  Ensemble: Average prediction                              â”‚
â”‚                                                             â”‚
â”‚  Output: ì˜ˆì¸¡ ìˆ˜ìµë¥  (ì—°ì†ê°’)                                 â”‚
â”‚          â†’ Top-K ì¢…ëª© ì„ ì •                                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ëª¨ë¸ë³„ ì„¸ë¶€ ì„¤ì •

#### 1. XGBoost Classifier
**íŒŒì¼**: `models/xgboost_model.py`

```python
# ê³µí†µ ì„¤ì •
tree_method='gpu_hist'          # GPU ê°€ì†
n_estimators=500                # íŠ¸ë¦¬ ê°œìˆ˜
learning_rate=0.1               # í•™ìŠµë¥ 
gamma=0                         # ìµœì†Œ loss reduction
subsample=0.8                   # ìƒ˜í”Œ ìƒ˜í”Œë§ ë¹„ìœ¨
colsample_bytree=0.8            # Feature ìƒ˜í”Œë§ ë¹„ìœ¨
objective='binary:logistic'     # Binary classification
eval_metric='logloss'           # Log loss

# Depth ë³€í˜• (ëª¨ë¸ ë‹¤ì–‘ì„± í™•ë³´)
clsmodel_0: max_depth=8         # Shallow (overfitting ë°©ì§€)
clsmodel_1: max_depth=9         # Medium
clsmodel_2: max_depth=10        # Deep (ë³µì¡í•œ íŒ¨í„´ í•™ìŠµ)
```

**ì™œ XGBoostì¸ê°€?**
- **Gradient Boosting ê¸°ë°˜**: ìˆœì°¨ì ìœ¼ë¡œ ì˜¤ì°¨ ë³´ì • â†’ ë†’ì€ ì •í™•ë„
- **Regularization**: L1/L2 ì •ê·œí™” ë‚´ì¥ â†’ Overfitting ë°©ì§€
- **Missing Value ì²˜ë¦¬**: ê²°ì¸¡ì¹˜ ìë™ ì²˜ë¦¬ (ì¬ë¬´ ë°ì´í„°ëŠ” ê²°ì¸¡ì¹˜ ë§ìŒ)
- **Feature Importance**: í•´ì„ ê°€ëŠ¥ì„± (ì–´ë–¤ ì¬ë¬´ë¹„ìœ¨ì´ ì¤‘ìš”í•œì§€ í™•ì¸)
- **GPU ì§€ì›**: ëŒ€ìš©ëŸ‰ ë°ì´í„° ë¹ ë¥¸ í•™ìŠµ

#### 2. LightGBM Classifier
```python
boosting_type='gbdt'            # Gradient Boosting Decision Tree
objective='binary'              # Binary classification
n_estimators=1000               # íŠ¸ë¦¬ ê°œìˆ˜ (XGBoostë³´ë‹¤ ë§ìŒ)
max_depth=8                     # íŠ¸ë¦¬ ê¹Šì´
learning_rate=0.1               # í•™ìŠµë¥ 
device='gpu'                    # GPU ì‚¬ìš©
boost_from_average=False        # Class imbalance ëŒ€ì‘
```

**ì™œ LightGBMì¸ê°€?**
- **ì†ë„**: XGBoostë³´ë‹¤ 2-3ë°° ë¹ ë¦„ (Leaf-wise growth)
- **ë©”ëª¨ë¦¬ íš¨ìœ¨**: ëŒ€ìš©ëŸ‰ ë°ì´í„° ì²˜ë¦¬ ìœ ë¦¬
- **Categorical Feature ì§€ì›**: Sector ë“± ë²”ì£¼í˜• ë³€ìˆ˜ ì§ì ‘ ì²˜ë¦¬
- **ì•™ìƒë¸” ë‹¤ì–‘ì„±**: XGBoostì™€ ë‹¤ë¥¸ ì•Œê³ ë¦¬ì¦˜ â†’ ì•™ìƒë¸” íš¨ê³¼ ê·¹ëŒ€í™”

#### 3. XGBoost Regressor
```python
tree_method='gpu_hist'
n_estimators=1000               # Classificationë³´ë‹¤ ë§ìŒ
learning_rate=0.1
gamma=0
subsample=0.8
colsample_bytree=0.8
objective='reg:squarederror'    # Regression
eval_metric='rmse'              # Root Mean Squared Error

model_0: max_depth=8            # Conservative
model_1: max_depth=10           # Aggressive
```

**Regression ì „ëµ**:
- Classification í•„í„° í†µê³¼ ì¢…ëª©ë§Œ ëŒ€ìƒ
- ì˜ˆì¸¡ê°’ ë†’ì€ ìˆœìœ¼ë¡œ ë­í‚¹ â†’ Top 3, Top 8, Top 16 ì„ ì •

### ì•™ìƒë¸” ì „ëµ

#### Classification Ensemble
```python
# Voting: 4ê°œ ëª¨ë¸ ì¤‘ ê³¼ë°˜ìˆ˜ê°€ "ìƒìŠ¹" ì˜ˆì¸¡í•œ ì¢…ëª©ë§Œ ì„ íƒ
y_probs = [model.predict_proba(X)[:, 1] for model in clsmodels]
threshold = np.percentile(y_probs, 92)  # ìƒìœ„ 8%ë§Œ í•„í„°ë§
ensemble_pred = (sum(y_probs > threshold) >= 2)  # 2ê°œ ì´ìƒ ë™ì˜
```

**Threshold ì¡°ì •**:
- ê¸°ë³¸: 50% (balanced)
- í˜„ì¬: 92% (aggressive) â†’ False Positive ìµœì†Œí™”

#### Regression Ensemble
```python
# Simple Average (weighted averageë„ ê°€ëŠ¥)
pred_0 = model_0.predict(X)
pred_1 = model_1.predict(X)
final_pred = (pred_0 + pred_1) / 2

# Classification í•„í„° ì ìš©
final_pred = np.where(cls_ensemble_pred == 0, -1, final_pred)
```

### ëŒ€ì²´ ëª¨ë¸ ì˜µì…˜

#### 1. CatBoost
**ì¥ì **:
- Categorical Feature ìµœì í™” (Sector, Industry)
- Overfitting ë°©ì§€ ê°•í•¨
- Ordered Boosting (Target Leakage ë°©ì§€)

**ì ìš© ë°©ë²•**:
```python
from models.catboost_model import CatBoostModel

model = CatBoostModel(task='classification')
model.build_model()
model.fit(X_train, y_train, cat_features=['sector', 'industry'])
```

#### 2. Neural Network (LSTM/Transformer)
**ì¥ì **:
- ì‹œê³„ì—´ íŒ¨í„´ í•™ìŠµ ê°•ë ¥
- ë³µì¡í•œ ë¹„ì„ í˜• ê´€ê³„ í¬ì°©

**ë‹¨ì **:
- í•´ì„ ë¶ˆê°€ëŠ¥ (Black Box)
- í•™ìŠµ ë°ì´í„° ëŒ€ëŸ‰ í•„ìš” (í˜„ì¬ ë°ì´í„° ë¶€ì¡± ê°€ëŠ¥ì„±)
- Overfitting ìœ„í—˜

**ì ìš© ê°€ëŠ¥ì„±**: ë°ì´í„° ì¶•ì  í›„ (5ë…„ ì´ìƒ ê¶Œì¥)

#### 3. Stacking Ensemble
**íŒŒì¼**: `models/ensemble.py`

```python
from models.ensemble import StackingEnsemble

# Base models
base_models = [
    ('xgb_8', xgb_model_8),
    ('xgb_9', xgb_model_9),
    ('xgb_10', xgb_model_10),
    ('lgb', lgb_model)
]

# Meta-learnerë¡œ Ridge Regression ì‚¬ìš©
ensemble = StackingEnsemble(
    base_models=base_models,
    task='classification',
    meta_learner='ridge',
    cv=5
)
ensemble.build_ensemble().fit(X_train, y_train)
predictions = ensemble.predict(X_test)
```

**ì¥ì **: Simple Votingë³´ë‹¤ ì„±ëŠ¥ í–¥ìƒ (Meta-learnerê°€ ìµœì  ê°€ì¤‘ì¹˜ í•™ìŠµ)

#### 4. AutoML (H2O, Auto-sklearn)
**ì¥ì **: ìë™ ëª¨ë¸ ì„ íƒ, í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”
**ë‹¨ì **: í•´ì„ì„± ë‚®ìŒ, ê³„ì‚° ë¹„ìš© ë†’ìŒ

---

## ğŸ”§ ì£¼ìš” ì»´í¬ë„ŒíŠ¸

### 1. Configuration (`config/`)

#### `context_loader.py`
```python
class MainContext:
    def __init__(self, config_dict):
        # DATA ì„¤ì •
        self.root_path = config['DATA']['ROOT_PATH']
        self.start_year = config['DATA']['START_YEAR']
        self.end_year = config['DATA']['END_YEAR']
        self.fmp_api_key = config['DATA']['API_KEY']

        # ML ì„¤ì •
        self.train_start_year = config['ML']['TRAIN_START_YEAR']
        self.train_end_year = config['ML']['TRAIN_END_YEAR']

        # BACKTEST ì„¤ì •
        self.rebalance_period = config['BACKTEST']['REBALANCE_PERIOD']
        self.top_k_num = config['BACKTEST']['TOP_K_NUM']

        # Logger ì´ˆê¸°í™”
        self.setup_logging()
```

**ì‚¬ìš© ì˜ˆ**:
```python
from config.context_loader import load_config, MainContext

config = load_config('config/conf.yaml')
ctx = MainContext(config)
```

#### `g_variables.py`
ì „ì—­ ë³€ìˆ˜ ë° Feature ë¦¬ìŠ¤íŠ¸ ì •ì˜

```python
# 139ê°œ ì¬ë¬´ ë¹„ìœ¨
ratio_col_list = [
    'roic', 'roe', 'roa',                  # ìˆ˜ìµì„±
    'priceToBookRatio', 'priceEarningsRatio',  # ë°¸ë¥˜ì—ì´ì…˜
    'debtToEquity', 'currentRatio',        # ì¬ë¬´ê±´ì „ì„±
    ...
]

# 158ê°œ ì ˆëŒ€ê°’ ì§€í‘œ
meaning_col_list = [
    'revenue', 'netIncome', 'eps',
    'totalAssets', 'totalDebt',
    ...
]

# 36ê°œ ì‹œê³„ì—´ íŠ¹ì„± ëŒ€ìƒ
cal_timefeature_col_list = [
    'roic', 'roe', 'netProfitMargin',
    ...
]

# Sector Mapping
sector_map = {
    'Software': 'Technology',
    'Semiconductors': 'Technology',
    'Pharmaceuticals': 'Healthcare',
    ...
}
```

#### `logger.py`
ë©€í‹°í”„ë¡œì„¸ì‹± ì•ˆì „ ë¡œê¹… ì‹œìŠ¤í…œ

```python
from config.logger import setup_logging, get_logger

setup_logging(log_level=20)  # INFO
logger = get_logger('my_module')

logger.info("Info message")
logger.warning("Warning message")
logger.error("Error message")
```

**íŠ¹ì§•**:
- **QueueHandler**: ë©€í‹°í”„ë¡œì„¸ì‹± í™˜ê²½ì—ì„œ ì•ˆì „
- **Color Output**: ì½˜ì†” ë¡œê·¸ ê°€ë…ì„±
- **Rotation**: ë¡œê·¸ íŒŒì¼ 10MBë§ˆë‹¤ ìë™ ë¶„í• 

### 2. Models (`models/`)

#### Base Model êµ¬ì¡°
```python
from models.base_model import BaseModel

class CustomModel(BaseModel):
    def build_model(self, params=None):
        # ëª¨ë¸ ìƒì„±
        pass

    def fit(self, X_train, y_train, X_val=None, y_val=None):
        # í•™ìŠµ
        pass

    def predict(self, X):
        # ì˜ˆì¸¡
        pass

    def evaluate(self, X_test, y_test):
        # í‰ê°€
        pass
```

**ì‚¬ìš© ì˜ˆ**:
```python
from models.xgboost_model import XGBoostModel

model = XGBoostModel(task='classification', config_name='depth_9')
model.build_model()
model.fit(X_train, y_train, X_val, y_val, early_stopping_rounds=50)
predictions = model.predict(X_test)
metrics = model.evaluate(X_test, y_test)
```

### 3. Training Pipeline (`training/`)

#### Hyperparameter Optimization
**íŒŒì¼**: `training/optimizer.py`

```python
from training.optimizer import OptunaOptimizer
from models.xgboost_model import XGBoostModel

# Search space ì •ì˜
search_space = {
    'max_depth': (5, 12),
    'learning_rate': (0.01, 0.3),
    'subsample': (0.6, 1.0),
    'colsample_bytree': (0.6, 1.0),
    'gamma': (0, 5)
}

optimizer = OptunaOptimizer(
    model_class=XGBoostModel,
    search_space=search_space,
    n_trials=100,
    cv_folds=5,
    scoring='accuracy'
)

best_params = optimizer.optimize(X_train, y_train)
```

**Optuna ì¥ì **:
- **TPE Sampler**: Bayesian Optimization (Grid Searchë³´ë‹¤ íš¨ìœ¨ì )
- **Pruning**: ì„±ëŠ¥ ë‚®ì€ trial ì¡°ê¸° ì¢…ë£Œ
- **Parallel**: ì—¬ëŸ¬ trial ë³‘ë ¬ ì‹¤í–‰

#### MLflow Tracking
**íŒŒì¼**: `training/mlflow_tracker.py`

```python
from training.mlflow_tracker import MLflowTracker

tracker = MLflowTracker(experiment_name='quant_trading')

with tracker.start_run(run_name='xgb_depth9'):
    tracker.log_params({
        'max_depth': 9,
        'learning_rate': 0.1,
        'n_estimators': 500
    })

    # í•™ìŠµ
    model.fit(X_train, y_train)

    # í‰ê°€
    metrics = model.evaluate(X_test, y_test)
    tracker.log_metrics(metrics)

    # ëª¨ë¸ ì €ì¥
    tracker.log_model(model, 'xgboost_model')
```

**MLflow UI**:
```bash
mlflow ui --backend-store-uri /path/to/mlruns
# http://localhost:5000
```

### 4. Backtesting (`backtest.py`)

```python
from backtest import Backtest, PlanHandler, DateHandler

# Plan ë¡œë“œ (ì‚¬ìš©ì ì •ì˜ ì „ëµ)
plan_handler = PlanHandler('plan.csv')

# Backtest ì‹¤í–‰
bt = Backtest(ctx, config, plan_handler)
bt.run()

# ë¦¬í¬íŠ¸ ìƒì„±
bt.generate_reports(['EVAL', 'RANK', 'AVG'])
```

**Plan ì˜ˆì‹œ** (`plan.csv`):
```
key,key_dir,weight,diff,base,base_dir
roe,descending,1.0,False,,
priceEarningsRatio,ascending,0.8,False,,
debtToEquity,ascending,0.5,False,,
price_dev,descending,2.0,True,,
```

**ë¦¬í¬íŠ¸ ì¢…ë¥˜**:
- **EVAL**: ê° ë¦¬ë°¸ëŸ°ì‹± ê¸°ê°„ë³„ ìˆ˜ìµë¥ , Sharpe Ratio, Max Drawdown
- **RANK**: ì„ ì • ì¢…ëª© ë¦¬ìŠ¤íŠ¸ ë° ìŠ¤ì½”ì–´
- **AVG**: ì „ì²´ ê¸°ê°„ í‰ê·  í†µê³„

---

## ğŸš€ ì‹¤í–‰ í”Œë¡œìš°

### ì „ì²´ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰

#### 1. Configuration ì„¤ì •
`config/conf.yaml` í¸ì§‘:
```yaml
DATA:
  ROOT_PATH: /home/user/Quant/data
  START_YEAR: 2015
  END_YEAR: 2023
  GET_FMP: Y  # ìƒˆ ë°ì´í„° ìˆ˜ì§‘í• ì§€ ì—¬ë¶€
  API_KEY: "your_fmp_api_key"

ML:
  RUN_REGRESSION: Y  # ML í•™ìŠµ ì‹¤í–‰ ì—¬ë¶€
  USE_NEW_MODELS: Y  # ìƒˆ ëª¨ë¸ ì•„í‚¤í…ì²˜ ì‚¬ìš©
  USE_MLFLOW: Y      # MLflow ì¶”ì  í™œì„±í™”
  TRAIN_START_YEAR: 2015
  TRAIN_END_YEAR: 2021
  TEST_START_YEAR: 2022
  TEST_END_YEAR: 2023

BACKTEST:
  RUN_BACKTEST: Y
  REBALANCE_PERIOD: 3  # 3ê°œì›” (ë¶„ê¸°ë³„)
  TOP_K_NUM: 100       # ìƒìœ„ 100ê°œ ì¢…ëª©
  REPORT_LIST: [EVAL, RANK, AVG]
```

#### 2. Main Script ì‹¤í–‰
```bash
cd Quant-refactoring
python main.py
```

**ì‹¤í–‰ ìˆœì„œ**:
```python
# main.py ë‚´ë¶€ íë¦„

# 1. Configuration ë¡œë“œ
config = load_config('config/conf.yaml')
ctx = MainContext(config)

# 2. ë°ì´í„° ìˆ˜ì§‘ (GET_FMP=Yì¼ ë•Œ)
if config['DATA']['GET_FMP'] == 'Y':
    fmp = FMP(ctx)
    fmp.collect()

    # Parquet ë³€í™˜
    storage = ParquetStorage(ctx.root_path)
    converter = ParquetConverter(ctx, storage)
    converter.insert_csv()
    converter.rebuild_table_view()

# 3. ML ë°ì´í„° ì¤€ë¹„
if config['ML']['RUN_REGRESSION'] == 'Y':
    aidata_maker = AIDataMaker(ctx, config)

    # 4. ëª¨ë¸ í•™ìŠµ
    regressor = Regressor(config)
    regressor.dataload()
    regressor.train()
    regressor.evaluation()
    regressor.latest_prediction()

# 5. ë°±í…ŒìŠ¤íŒ…
if config['BACKTEST']['RUN_BACKTEST'] == 'Y':
    plan_handler = PlanHandler(ctx, 'plan.csv')
    bt = Backtest(ctx, config, plan_handler)
    bt.run()
```

### ê°œë³„ ì»´í¬ë„ŒíŠ¸ ì‹¤í–‰

#### ë°ì´í„° ìˆ˜ì§‘ë§Œ
```bash
python -c "
from config.context_loader import load_config, MainContext
from data_collector.fmp import FMP

config = load_config('config/conf.yaml')
ctx = MainContext(config)

fmp = FMP(ctx)
fmp.collect()
"
```

#### ML í•™ìŠµë§Œ
```bash
python -c "
from config.context_loader import load_config, MainContext
from training.regressor import Regressor

config = load_config('config/conf.yaml')
regressor = Regressor(config)

regressor.dataload()
regressor.train()
regressor.evaluation()
"
```

#### ìµœì‹  ì˜ˆì¸¡ë§Œ
```bash
python -c "
from config.context_loader import load_config
from training.regressor import Regressor

config = load_config('config/conf.yaml')
regressor = Regressor(config)

regressor.dataload()
regressor.latest_prediction()
# â†’ /data/MODELS/latest_prediction.csv
"
```

### ìŠ¤í¬ë¦½íŠ¸ ê¸°ë°˜ ì‹¤í–‰

#### ì „ì²´ íŒŒì´í”„ë¼ì¸
```bash
python scripts/run_full_pipeline.py
```

#### ëª¨ë¸ ë¹„êµ
```bash
python scripts/run_model_comparison.py
# ì—¬ëŸ¬ ëª¨ë¸ ì„¤ì • ì„±ëŠ¥ ë¹„êµ
```

#### ë¦¬ë°¸ëŸ°ì‹± ìµœì í™”
```bash
python scripts/run_rebalance_optimization.py
# 1ê°œì›”, 3ê°œì›”, 6ê°œì›”, 12ê°œì›” ë¦¬ë°¸ëŸ°ì‹± ì„±ê³¼ ë¹„êµ
```

#### ì„¹í„°ë³„ íŠ¸ë ˆì´ë”©
```bash
python scripts/run_sector_trading.py
# ì„¹í„°ë³„ ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡
```

---

## âš  í˜„ì¬ í•œê³„ì  ë° ê°œì„  ë°©í–¥

### í•œê³„ì 

#### 1. ë°ì´í„° í’ˆì§ˆ
**ë¬¸ì œ**:
- FMP API ë°ì´í„° ê²°ì¸¡ì¹˜ ë§ìŒ (íŠ¹íˆ ì†Œí˜•ì£¼)
- ì¼ë¶€ ì¬ë¬´ì§€í‘œ ì˜¤ë¥˜ (API ì œê³µì‚¬ ë¬¸ì œ)
- ìƒì¥íì§€ ì¢…ëª© ë°ì´í„° ë¶ˆì™„ì „

**ê°œì„  ë°©í–¥**:
- ë‹¤ì¤‘ ë°ì´í„° ì†ŒìŠ¤ í†µí•© (Yahoo Finance, Alpha Vantage)
- ë°ì´í„° ê²€ì¦ ë¡œì§ ê°•í™” (`validation/` ëª¨ë“ˆ í™œìš©)
- ì´ìƒì¹˜ íƒì§€ ë° ìë™ ë³´ì •

#### 2. Feature Engineering
**ë¬¸ì œ**:
- ê³ ì •ëœ Feature ë¦¬ìŠ¤íŠ¸ (139ê°œ ratio + 36ê°œ ì‹œê³„ì—´)
- Feature Selection ë¯¸í¡ (ì¤‘ìš”ë„ ë‚®ì€ feature ë‹¤ìˆ˜)
- Sector/Industry ì •ë³´ í™œìš© ë¶€ì¡±

**ê°œì„  ë°©í–¥**:
- **Feature Selection**: `feature_engineering/feature_selector.py` í™œìš©
  ```python
  from feature_engineering.feature_selector import FeatureSelector

  selector = FeatureSelector(method='importance', threshold=0.01)
  selected_features = selector.fit_transform(X_train, y_train)
  ```
- **Automated Feature Engineering**: Featuretools ë„ì…
- **Sector-specific Features**: ì„¹í„°ë³„ ì¤‘ìš” ì§€í‘œ ë‹¤ë¥´ê²Œ ì ìš©

#### 3. ëª¨ë¸ ì„±ëŠ¥
**ë¬¸ì œ**:
- Classification Accuracy: 55-60% (ë†’ì§€ ì•ŠìŒ)
- Regression RMSE: ê°œì„  ì—¬ì§€ ìˆìŒ
- ì‹œì¥ ë³€ë™ì„± ë†’ì€ ì‹œê¸° ì„±ëŠ¥ ì €í•˜

**ê°œì„  ë°©í–¥**:
- **ì•™ìƒë¸” ê³ ë„í™”**: Stacking Ensemble ì ìš© (í˜„ì¬ Simple Voting)
  ```python
  from models.ensemble import StackingEnsemble

  ensemble = StackingEnsemble(
      base_models=[...],
      meta_learner='ridge',
      cv=5
  )
  ```
- **í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”**: Optunaë¡œ ì „ì—­ ìµœì í™”
  ```bash
  python scripts/optimize_hyperparameters.py --n_trials 200
  ```
- **Deep Learning ì‹¤í—˜**: LSTM, Transformer (ë°ì´í„° ì¶©ë¶„ ì‹œ)

#### 4. ë°±í…ŒìŠ¤íŒ… í•œê³„
**ë¬¸ì œ**:
- ê±°ë˜ ë¹„ìš© ë¯¸ë°˜ì˜ (ìˆ˜ìˆ˜ë£Œ, ìŠ¬ë¦¬í”¼ì§€)
- ìœ ë™ì„± ì œì•½ ë¯¸ê³ ë ¤ (ëŒ€ëŸ‰ ë§¤ìˆ˜/ë§¤ë„ ì‹œ ê°€ê²© ì˜í–¥)
- Market Regime ë³€í™” ë¯¸ë°˜ì˜ (ë¶ˆì¥/ì•½ì¥)

**ê°œì„  ë°©í–¥**:
- **ê±°ë˜ ë¹„ìš© ëª¨ë¸ë§**:
  ```python
  # backtest.py ìˆ˜ì •
  entry_cost = entry_price * 0.001  # 0.1% ìˆ˜ìˆ˜ë£Œ
  exit_cost = exit_price * 0.001
  net_return = gross_return - entry_cost - exit_cost
  ```
- **Slippage ëª¨ë¸**:
  ```python
  slippage = entry_price * 0.002  # 0.2% ìŠ¬ë¦¬í”¼ì§€
  actual_entry = entry_price * (1 + slippage)
  ```
- **Volume Filter**: ì¼í‰ê·  ê±°ë˜ëŒ€ê¸ˆ í•˜ìœ„ 50% ì œì™¸ (ì´ë¯¸ ì ìš© ì¤‘)

#### 5. ì‹¤ì‹œê°„ íŠ¸ë ˆì´ë”© ì§€ì› ë¶€ì¡±
**ë¬¸ì œ**:
- ì¼ë³„ ê°€ê²©ë§Œ ì§€ì› (ë¶„/ì´ˆ ë‹¨ìœ„ ë¯¸ì§€ì›)
- ì‹¤ì‹œê°„ ë°ì´í„° ìˆ˜ì§‘ ì—†ìŒ
- ìë™ ì£¼ë¬¸ ê¸°ëŠ¥ ì—†ìŒ

**ê°œì„  ë°©í–¥**:
- **ì‹¤ì‹œê°„ ë°ì´í„°**: WebSocket API ì—°ë™
- **ìë™ ë§¤ë§¤**: Interactive Brokers API, Alpaca API ì—°ë™
- **ëª¨ë‹ˆí„°ë§**: `monitoring/performance_monitor.py` í™œìš©
  ```python
  from monitoring.performance_monitor import PerformanceMonitor

  monitor = PerformanceMonitor()
  monitor.track_prediction_accuracy(y_true, y_pred)
  monitor.track_portfolio_value(current_value)
  monitor.send_alert_if_drawdown_exceeds(threshold=0.1)
  ```

### ì¶”ê°€ í•„ìš” ê¸°ëŠ¥

#### 1. Risk Management
**í˜„ì¬**: ë‹¨ìˆœ Top-K ì„ ì • (ë™ì¼ ê°€ì¤‘)

**ê°œì„ **:
```python
# portfolio_optimization/ ì¶”ê°€
from portfolio_optimization.risk_manager import RiskManager

risk_mgr = RiskManager(
    max_position_size=0.05,    # ì¢…ëª©ë‹¹ 5% ì œí•œ
    max_sector_exposure=0.30,  # ì„¹í„°ë‹¹ 30% ì œí•œ
    stop_loss=0.10,            # 10% ì†ì ˆ
    take_profit=0.20           # 20% ìµì ˆ
)

portfolio = risk_mgr.allocate_weights(predictions, prices)
```

#### 2. í¬íŠ¸í´ë¦¬ì˜¤ ìµœì í™”
**ì¶”ê°€ ì•Œê³ ë¦¬ì¦˜**:
- **Mean-Variance Optimization** (Markowitz)
- **Black-Litterman Model** (ì˜ˆì¸¡ ê²°í•©)
- **Risk Parity** (ìœ„í—˜ ê· ë“± ë°°ë¶„)

```python
from portfolio_optimization.optimizer import PortfolioOptimizer

optimizer = PortfolioOptimizer(method='mean_variance')
weights = optimizer.optimize(
    expected_returns=predictions,
    covariance_matrix=cov_matrix,
    risk_aversion=2.5
)
```

#### 3. Time Series CV ê°•í™”
**í˜„ì¬**: Train/Test ë‹¨ìˆœ ë¶„í• 

**ê°œì„ **:
```python
from validation.time_series_cv import TimeSeriesCV

cv = TimeSeriesCV(n_splits=5, gap=3)  # 3ê°œì›” gap
for train_idx, test_idx in cv.split(X):
    X_train, X_test = X[train_idx], X[test_idx]
    # ê° foldë³„ í•™ìŠµ ë° í‰ê°€
```

**Walk-Forward Analysis**:
```python
from validation.walk_forward import WalkForwardAnalysis

wfa = WalkForwardAnalysis(
    train_period=12,  # 12ê°œì›” í•™ìŠµ
    test_period=3,    # 3ê°œì›” í…ŒìŠ¤íŠ¸
    step=3            # 3ê°œì›”ì”© ì´ë™
)
results = wfa.run(X, y, model)
```

#### 4. Explainability (ì„¤ëª… ê°€ëŠ¥ì„±)
**SHAP ë„ì…**:
```python
import shap

explainer = shap.TreeExplainer(model)
shap_values = explainer.shap_values(X_test)

# ì¢…ëª©ë³„ ì˜ˆì¸¡ ì´ìœ  ì‹œê°í™”
shap.waterfall_plot(shap_values[0])

# Feature Importance
shap.summary_plot(shap_values, X_test)
```

**ì‚¬ìš© ì‚¬ë¡€**:
- "ì™œ ì´ ì¢…ëª©ì„ ì¶”ì²œí–ˆë‚˜?" â†’ SHAP ê°’ìœ¼ë¡œ ì„¤ëª…
- íˆ¬ìì ì‹ ë¢°ë„ í–¥ìƒ

#### 5. ëŒ€ì²´ ë°ì´í„° í†µí•©
**ì¶”ê°€ ë°ì´í„° ì†ŒìŠ¤**:
- **ë‰´ìŠ¤ ê°ì„± ë¶„ì„**: FinBERT, GPT API
- **ì†Œì…œ ë¯¸ë””ì–´**: Twitter/Reddit ê°ì„± (WallStreetBets)
- **ê±°ë˜ëŸ‰ ì´ìƒ íƒì§€**: Unusual Volume Analysis
- **ì˜µì…˜ ë°ì´í„°**: Put/Call Ratio

```python
# alternative_data/ ì¶”ê°€
from alternative_data.news_sentiment import NewsSentiment

news = NewsSentiment(api_key='news_api_key')
sentiment_scores = news.get_sentiment(symbols, start_date, end_date)

# Featureë¡œ ì¶”ê°€
X['news_sentiment'] = sentiment_scores
```

#### 6. Regime Detection (ì‹œì¥ êµ­ë©´ ê°ì§€)
**ëª©ì **: ë¶ˆì¥/ì•½ì¥ì— ë”°ë¼ ì „ëµ ë³€ê²½

```python
from market_analysis.regime_detector import RegimeDetector

detector = RegimeDetector(method='hmm')  # Hidden Markov Model
regimes = detector.fit_predict(price_history)

# Regimeë³„ ëª¨ë¸ í•™ìŠµ
bull_model = train_model(X[regimes == 'bull'], y[regimes == 'bull'])
bear_model = train_model(X[regimes == 'bear'], y[regimes == 'bear'])
```

---

## ğŸ“ ìš”ì•½

### ì‹œìŠ¤í…œ ê°•ì 
1. **End-to-End ìë™í™”**: ë°ì´í„° ìˆ˜ì§‘ â†’ í•™ìŠµ â†’ ì˜ˆì¸¡ â†’ ë°±í…ŒìŠ¤íŒ…
2. **ëª¨ë“ˆí™” ì„¤ê³„**: ê° ì»´í¬ë„ŒíŠ¸ ë…ë¦½ì  ì‹¤í–‰ ê°€ëŠ¥
3. **ì•™ìƒë¸” ì „ëµ**: ì—¬ëŸ¬ ëª¨ë¸ ì¡°í•©ìœ¼ë¡œ ì•ˆì •ì„± í™•ë³´
4. **í™•ì¥ ê°€ëŠ¥**: ìƒˆ ëª¨ë¸, ë°ì´í„°, ì „ëµ ì‰½ê²Œ ì¶”ê°€
5. **ì‹¤í—˜ ì¶”ì **: MLflowë¡œ ëª¨ë“  ì‹¤í—˜ ê¸°ë¡
6. **ì„±ëŠ¥ ìµœì í™”**: Parquet, GPU, Multiprocessing

### ê°œì„  ìš°ì„ ìˆœìœ„
1. **Feature Selection** (ì¦‰ì‹œ ì ìš© ê°€ëŠ¥, í° íš¨ê³¼)
2. **Stacking Ensemble** (ì„±ëŠ¥ í–¥ìƒ ì¦‰ì‹œ)
3. **ê±°ë˜ ë¹„ìš© ë°˜ì˜** (ë°±í…ŒìŠ¤íŠ¸ í˜„ì‹¤í™”)
4. **Risk Management** (ì•ˆì •ì„± í™•ë³´)
5. **SHAP Explainability** (ì‹ ë¢°ë„ í–¥ìƒ)

### ë‹¤ìŒ ë‹¨ê³„ ì œì•ˆ
1. **ë‹¨ê¸°** (1-2ì£¼):
   - Feature Selection ì ìš© â†’ í•™ìŠµ ì†ë„ í–¥ìƒ
   - Stacking Ensemble ì‹¤í—˜ â†’ ì„±ëŠ¥ ê°œì„ 
   - ê±°ë˜ ë¹„ìš© ëª¨ë¸ë§ â†’ ë°±í…ŒìŠ¤íŠ¸ ì •í™•ë„ í–¥ìƒ

2. **ì¤‘ê¸°** (1-2ê°œì›”):
   - Optuna í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” â†’ ëª¨ë“  ëª¨ë¸ ìµœì í™”
   - Time Series CV ê°•í™” â†’ Overfitting ë°©ì§€
   - Risk Management ëª¨ë“ˆ ì¶”ê°€ â†’ ì•ˆì •ì„± í™•ë³´

3. **ì¥ê¸°** (3-6ê°œì›”):
   - ëŒ€ì²´ ë°ì´í„° í†µí•© (ë‰´ìŠ¤, ì†Œì…œë¯¸ë””ì–´)
   - Deep Learning ì‹¤í—˜ (LSTM, Transformer)
   - ì‹¤ì‹œê°„ íŠ¸ë ˆì´ë”© ì‹œìŠ¤í…œ êµ¬ì¶•

---

## ğŸ“š ì°¸ê³  ìë£Œ

### ì£¼ìš” íŒŒì¼ ìœ„ì¹˜
- **Configuration**: `config/conf.yaml`
- **Main Entry**: `main.py`
- **Data Collection**: `data_collector/fmp.py`
- **Feature Engineering**: `training/make_mldata.py`
- **Model Training**: `training/regressor.py`
- **Models**: `models/*.py`
- **Backtesting**: `backtest.py`
- **Examples**: `examples/*.py`
- **Scripts**: `scripts/*.py`

### ë¡œê¹… í™•ì¸
```bash
tail -f logs/quant_trading.log
```

### MLflow UI
```bash
mlflow ui --backend-store-uri /home/user/Quant/data/mlruns
# http://localhost:5000
```

### ë°ì´í„° ìœ„ì¹˜
```
/home/user/Quant/data/
â”œâ”€â”€ stock_list/
â”œâ”€â”€ financial_statements/
â”œâ”€â”€ key_metrics/
â”œâ”€â”€ historical_price/
â”œâ”€â”€ VIEW/                   # í†µí•© ë·°
â”œâ”€â”€ ml_per_year/            # ML í•™ìŠµ ë°ì´í„°
â””â”€â”€ MODELS/                 # í•™ìŠµëœ ëª¨ë¸
```

---

**ë¬¸ì„œ ë²„ì „**: 1.0
**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸**: 2025-10-27
**ì‘ì„±ì**: Claude AI + Development Team

ê¶ê¸ˆí•œ ì ì´ë‚˜ ê°œì„  ì œì•ˆì´ ìˆìœ¼ë©´ GitHub Issuesì— ë“±ë¡í•´ì£¼ì„¸ìš”.
